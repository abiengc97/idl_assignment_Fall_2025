{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3ytyXW-7Q6o"
      },
      "source": [
        "# Setup\n",
        "-  Follow the setup instructions based on your preferred environment!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeJDFDo87Q6s"
      },
      "source": [
        "## Local"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xg5oyR8XzQRY"
      },
      "source": [
        "One of our key goals in designing this assignment is to allow you to complete most of the preliminary implementation work locally.  \n",
        "We highly recommend that you **pass all tests locally** using the provided `hw4_data_subset` before moving to a GPU runtime.  \n",
        "To do this, simply:\n",
        "\n",
        "### Create a new conda environment\n",
        "```bash\n",
        "# Be sure to deactivate any active environments first\n",
        "conda create -n hw4 python=3.12.4\n",
        "```\n",
        "\n",
        "### Activate the conda environment\n",
        "```bash\n",
        "conda activate hw4\n",
        "```\n",
        "\n",
        "### Install the dependencies using the provided `requirements.txt`\n",
        "```bash\n",
        "pip install --no-cache-dir --ignore-installed -r requirements.txt\n",
        "```\n",
        "\n",
        "### Ensure that your notebook is in the same working directory as the `Handout`\n",
        "This can be achieved by:\n",
        "1. Physically moving the notebook into the handout directory.\n",
        "2. Changing the notebookâ€™s current working directory to the handout directory using the os.chdir() function.\n",
        "\n",
        "### Open the notebook and select the newly created environment from the kernel selector.\n",
        "\n",
        "If everything was done correctly, You should see atleast the following files in your current working directory after running `!ls`:\n",
        "```\n",
        ".\n",
        "â”œâ”€â”€ README.md\n",
        "â”œâ”€â”€ requirements.txt\n",
        "â”œâ”€â”€ hw4lib/\n",
        "â”œâ”€â”€ mytorch/\n",
        "â”œâ”€â”€ tests/\n",
        "â””â”€â”€ hw4_data_subset/\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tub92oPW7Q6t"
      },
      "source": [
        "## Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5qfxCxq7l-f"
      },
      "source": [
        "### Step 1: Get your handout\n",
        "- See writeup for recommended approaches."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfOQStjw7Q6w"
      },
      "source": [
        "### Step 2: Install Dependencies\n",
        "- `NOTE`: Your runtime will be restarted to ensure all dependencies are updated.\n",
        "- `NOTE`: You will see a runtime crashed message, this was intentionally done. Simply move on to the next cell."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhPm0t5d7Q6z"
      },
      "source": [
        "# Imports\n",
        "\n",
        "- If your setup was done correctly, you should be able to run the following cell without any issues."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "YAJF1-E87Q6z"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "from hw4lib.data import (\n",
        "    H4Tokenizer,\n",
        "    LMDataset,\n",
        "    verify_dataloader\n",
        ")\n",
        "from hw4lib.model import (\n",
        "    CausalMask,\n",
        "    PadMask,\n",
        "    PositionalEncoding,\n",
        "    DecoderOnlyTransformer\n",
        ")\n",
        "from hw4lib.utils import (\n",
        "    create_optimizer,\n",
        "    create_scheduler,\n",
        "    plot_lr_schedule\n",
        ")\n",
        "from hw4lib.trainers import (\n",
        "    LMTrainer,\n",
        ")\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import yaml\n",
        "import gc\n",
        "import torch\n",
        "from torchinfo import summary\n",
        "import os\n",
        "import json\n",
        "import tarfile\n",
        "import shutil\n",
        "import wandb\n",
        "import yaml\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Q4Ccp-M7Q60"
      },
      "source": [
        "# Implementations\n",
        "\n",
        "- `NOTE`: All of these implementations have detailed specification, implementation details, and hints in their respective source files. Make sure to read all of them in their entirety to understand the implementation details!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vqefJri7Q60"
      },
      "source": [
        "## MyTorch Implementations\n",
        "- Modify your `Linear` implementation from HW1P1 to support arbitrary number of dimensions in `mytorch/nn/linear.py`.\n",
        "- Modify your `Softmax` implementation from HW1P1 to support arbitrary number of dimensions in `mytorch/nn/activation.py`.\n",
        "- Implement the `ScaledDotProductAttention` class in `mytorch/nn/scaled_dot_product_attention.py`.\n",
        "- Implement the `MultiHeadAttention` class in `mytorch/nn/multi_head_attention.py`.\n",
        "- Run the cell below to check your implementations.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8hb5VAN7Q60"
      },
      "source": [
        "## Dataset Implementation\n",
        "- Familiarize yourself with the `tokenize`, `encode`, and `decode` methods of the `H4Tokenizer` class in `hw4lib/data/tokenizer.py`. You will need to make use of these methods in both `HW4P1` and `HW4P2` both in the dataset implementations and during decoding.\n",
        "- Implement the `LMDataset` class in `hw4lib/data/lm_dataset.py`.\n",
        "    - You will have to implement parts of `__init__` and completely implement the `__len__`, `__getitem__` and `collate_fn` methods.\n",
        "- Run the cell below to check your implementation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "D1oCYvlJ7Q60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading transcripts for train partition...\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 267/267 [00:00<00:00, 8851.26it/s]\n",
            "\n",
            "\u001b[95m================================================================================\n",
            "Running tests for category: LMDataset\n",
            "--------------------------------------------------------------------------------\u001b[0m\n",
            "\n",
            "\u001b[94m[01/01]    Running:  Test the LMDataset class\u001b[0m\n",
            "Testing __init__ method ...\n",
            "Test Passed: Text files are sorted.\n",
            "Test Passed: Shifted and golden transcripts are aligned.\n",
            "Test Passed: All transcripts are decoded correctly after removing SOS and EOS tokens.\n",
            "Testing __getitem__ method ...\n",
            "Test Passed: SOS and EOS tokens are correctly placed for samples.\n",
            "Test Passed: All transcripts are decoded correctly after removing SOS and EOS tokens.\n",
            "Testing collate_fn method ...\n",
            "Test Passed: Transcript batch has correct dimensions (2D tensor).\n",
            "Test Passed: Transcript lengths are consistent with the batch size.\n",
            "Test Passed: All sequences are padded to the same length.\n",
            "Test Passed: Padding values are correct.\n",
            "Test Passed: Batch transcripts are of correct data type.\n",
            "\u001b[92m[01/01]    PASSED:   Test the LMDataset class\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[95m================================================================================\n",
            "                                  Test Summary                                  \n",
            "================================================================================\u001b[0m\n",
            "\u001b[93mCategory:    LMDataset                     \n",
            "Results:     1/1 tests passed (100.0%)\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python -m tests.test_dataset_lm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Fl_9Vv117Q66"
      },
      "outputs": [],
      "source": [
        "with open('config.yaml', 'r') as file:\n",
        "    config = yaml.safe_load(file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bu56OILL7Q66"
      },
      "source": [
        "## Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "XBrysj6-7Q66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "                          Tokenizer Configuration (5k)                          \n",
            "--------------------------------------------------------------------------------\n",
            "Vocabulary size:     5000\n",
            "\n",
            "Special Tokens:\n",
            "PAD:              0\n",
            "UNK:              1\n",
            "MASK:             2\n",
            "SOS:              3\n",
            "EOS:              4\n",
            "BLANK:            5\n",
            "\n",
            "Validation Example:\n",
            "--------------------------------------------------------------------------------\n",
            "Input text:  [SOS]HI DEEP LEARNERS[EOS]\n",
            "Tokens:      ['[SOS]', 'H', 'I', 'Ä DEEP', 'Ä LEARN', 'ERS', '[EOS]']\n",
            "Token IDs:   [3, 14, 15, 1169, 2545, 214, 4]\n",
            "Decoded:     [SOS]HI DEEP LEARNERS[EOS]\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "Tokenizer = H4Tokenizer(\n",
        "    token_map  = config['tokenization']['token_map'],\n",
        "    token_type = config['tokenization']['token_type']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-vsGdfu7Q66"
      },
      "source": [
        "## Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "OCR3fGoL7Q66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading transcripts for train partition...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 267/267 [00:00<00:00, 8768.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading transcripts for val partition...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 5091.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading transcripts for test partition...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 5922.96it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "597082"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset  = LMDataset(\n",
        "    partition  = config['data']['train_partition'],\n",
        "    config     = config['data'],\n",
        "    tokenizer  = Tokenizer\n",
        ")\n",
        "\n",
        "val_dataset    = LMDataset(\n",
        "    partition  = config['data']['val_partition'],\n",
        "    config     = config['data'],\n",
        "    tokenizer  = Tokenizer\n",
        ")\n",
        "\n",
        "test_dataset   = LMDataset(\n",
        "    partition  = config['data']['test_partition'],\n",
        "    config     = config['data'],\n",
        "    tokenizer  = Tokenizer\n",
        ")\n",
        "\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qf8Y_COP7Q66"
      },
      "source": [
        "## Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "0GajQ0LX7Q66"
      },
      "outputs": [],
      "source": [
        "train_loader    = DataLoader(\n",
        "    dataset     = train_dataset,\n",
        "    batch_size  = config['data']['batch_size'],\n",
        "    shuffle     = True,\n",
        "    num_workers = config['data']['NUM_WORKERS'] if device == 'cuda' else 0,\n",
        "    pin_memory  = True,\n",
        "    collate_fn  = train_dataset.collate_fn\n",
        ")\n",
        "\n",
        "val_loader      = DataLoader(\n",
        "    dataset     = val_dataset,\n",
        "    batch_size  = config['data']['batch_size'],\n",
        "    shuffle     = False,\n",
        "    num_workers = config['data']['NUM_WORKERS'] if device == 'cuda' else 0,\n",
        "    pin_memory  = True,\n",
        "    collate_fn  = val_dataset.collate_fn\n",
        ")\n",
        "\n",
        "test_loader     = DataLoader(\n",
        "    dataset     = test_dataset,\n",
        "    batch_size  = config['data']['batch_size'],\n",
        "    shuffle     = False,\n",
        "    num_workers = config['data']['NUM_WORKERS'] if device == 'cuda' else 0,\n",
        "    pin_memory  = True,\n",
        "    collate_fn  = test_dataset.collate_fn\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLKjKWJQ7Q67"
      },
      "source": [
        "### Dataloader Verification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCrlXlZH7Q67"
      },
      "source": [
        "## Calculate Max Transcript Length\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIGxOLDU7Q67"
      },
      "source": [
        "Calculating the maximum transcript length across your dataset is a crucial step when working with certain transformer models.\n",
        "-  We'll use sinusoidal positional encodings that must be precomputed up to a fixed maximum length.\n",
        "- This maximum length is a hyperparameter that determines:\n",
        "  - How long of a sequence your model can process\n",
        "  - The size of your positional encoding matrix\n",
        "  - Memory requirements during training and inference\n",
        "- `Requirements`: For this assignment, ensure your positional encodings can accommodate at least the longest sequence in your dataset to prevent truncation. However, you can set this value higher if you anticipate using your language model to work with longer sequences in future tasks (hint: this might be useful for P2! ðŸ˜‰)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "iWAWHucJ7Q67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Global Max Transcript Length   : 70\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "max_transcript_length = max(train_dataset.text_max_len, val_dataset.text_max_len, test_dataset.text_max_len)\n",
        "print(\"=\"*50)\n",
        "print(f\"{'Global Max Transcript Length':<30} : {max_transcript_length}\")\n",
        "print(\"=\"*50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ot4OuRE27Q67"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "qL2-8IbL7Q67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of shifted_transcripts :  torch.Size([128, 70])\n",
            "Shape of golden_transcripts  :  torch.Size([128, 70])\n",
            "Shape of transcript_lengths  :  torch.Size([128])\n",
            "===============================================================================================\n",
            "Layer (type:depth-idx)                        Output Shape              Param #\n",
            "===============================================================================================\n",
            "DecoderOnlyTransformer                        [128, 70, 5000]           --\n",
            "â”œâ”€Embedding: 1-1                              [128, 70, 512]            2,560,000\n",
            "â”œâ”€PositionalEncoding: 1-2                     [128, 70, 512]            --\n",
            "â”œâ”€Dropout: 1-3                                [128, 70, 512]            --\n",
            "â”œâ”€ModuleList: 1-4                             --                        --\n",
            "â”‚    â””â”€SelfAttentionDecoderLayer: 2-1         [128, 70, 512]            1,024\n",
            "â”‚    â”‚    â””â”€SelfAttentionLayer: 3-1           [128, 70, 512]            1,051,648\n",
            "â”‚    â”‚    â””â”€FeedForwardLayer: 3-2             [128, 70, 512]            2,100,736\n",
            "â”‚    â””â”€SelfAttentionDecoderLayer: 2-2         [128, 70, 512]            1,024\n",
            "â”‚    â”‚    â””â”€SelfAttentionLayer: 3-3           [128, 70, 512]            1,051,648\n",
            "â”‚    â”‚    â””â”€FeedForwardLayer: 3-4             [128, 70, 512]            2,100,736\n",
            "â”‚    â””â”€SelfAttentionDecoderLayer: 2-3         [128, 70, 512]            1,024\n",
            "â”‚    â”‚    â””â”€SelfAttentionLayer: 3-5           [128, 70, 512]            1,051,648\n",
            "â”‚    â”‚    â””â”€FeedForwardLayer: 3-6             [128, 70, 512]            2,100,736\n",
            "â”‚    â””â”€SelfAttentionDecoderLayer: 2-4         [128, 70, 512]            1,024\n",
            "â”‚    â”‚    â””â”€SelfAttentionLayer: 3-7           [128, 70, 512]            1,051,648\n",
            "â”‚    â”‚    â””â”€FeedForwardLayer: 3-8             [128, 70, 512]            2,100,736\n",
            "â”œâ”€LayerNorm: 1-5                              [128, 70, 512]            1,024\n",
            "â”œâ”€Linear: 1-6                                 [128, 70, 5000]           2,565,000\n",
            "===============================================================================================\n",
            "Total params: 17,739,656\n",
            "Trainable params: 17,739,656\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 1.73\n",
            "===============================================================================================\n",
            "Input size (MB): 0.07\n",
            "Forward/backward pass size (MB): 1459.40\n",
            "Params size (MB): 54.13\n",
            "Estimated Total Size (MB): 1513.61\n",
            "===============================================================================================\n"
          ]
        }
      ],
      "source": [
        "model_config = config['model']\n",
        "model_config.update({\n",
        "    'max_len': max_transcript_length,\n",
        "    'num_classes': Tokenizer.vocab_size\n",
        "})\n",
        "model = DecoderOnlyTransformer(**model_config)\n",
        "\n",
        "# Get some inputs from the text loader\n",
        "for batch in train_loader:\n",
        "    shifted_transcripts, golden_transcripts, transcript_lengths = batch\n",
        "    print(\"Shape of shifted_transcripts : \", shifted_transcripts.shape)\n",
        "    print(\"Shape of golden_transcripts  : \", golden_transcripts.shape)\n",
        "    print(\"Shape of transcript_lengths  : \", transcript_lengths.shape)\n",
        "    break\n",
        "\n",
        "model_stats = summary(model, input_data=[shifted_transcripts, transcript_lengths])\n",
        "print(model_stats)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SH973f3x7Q67"
      },
      "source": [
        "## Wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "oz7os7UA7Q68"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wandb.login(key=\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQAemeOM7Q68"
      },
      "source": [
        "## Trainer\n",
        "\n",
        "Every time you run the trainer, it will create a new directory in the `expts` folder with the following structure:\n",
        "```\n",
        "expts/\n",
        "    â””â”€â”€ {run_name}/\n",
        "        â”œâ”€â”€ config.yaml\n",
        "        â”œâ”€â”€ model_arch.txt\n",
        "        â”œâ”€â”€ checkpoints/\n",
        "        â”‚   â”œâ”€â”€ checkpoint-best-metric-model.pth\n",
        "        â”‚   â””â”€â”€ checkpoint-last-epoch-model.pth\n",
        "        â”œâ”€â”€ attn/\n",
        "        â”‚   â””â”€â”€ {attention visualizations}\n",
        "        â””â”€â”€ text/\n",
        "            â””â”€â”€ {generated text outputs}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "UcvGSnWi7Q68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.2"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/agcheria/idl_assignment_Fall_2025/HW4/HW4P1/IDL-HW4/IDL-HW4/wandb/run-20251112_012533-8hbndazw</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/agcheria-carnegie-mellon-university/Set-Project-Name-Here/runs/8hbndazw' target=\"_blank\">test-lm</a></strong> to <a href='https://wandb.ai/agcheria-carnegie-mellon-university/Set-Project-Name-Here' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/agcheria-carnegie-mellon-university/Set-Project-Name-Here' target=\"_blank\">https://wandb.ai/agcheria-carnegie-mellon-university/Set-Project-Name-Here</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/agcheria-carnegie-mellon-university/Set-Project-Name-Here/runs/8hbndazw' target=\"_blank\">https://wandb.ai/agcheria-carnegie-mellon-university/Set-Project-Name-Here/runs/8hbndazw</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "trainer = LMTrainer(\n",
        "    model=model,\n",
        "    tokenizer=Tokenizer,\n",
        "    config=config,\n",
        "    run_name=\"test-lm\",\n",
        "    config_file=\"config.yaml\",\n",
        "    device=device\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJREaFhqiPrT"
      },
      "source": [
        "### Setup Optimizer and Scheduler\n",
        "\n",
        "You can set your own optimizer and scheduler by setting the class members in the `LMTrainer` class.\n",
        "Eg:\n",
        "```python\n",
        "trainer.optimizer = optim.AdamW(model.parameters(), lr=config['optimizer']['lr'], weight_decay=config['optimizer']['weight_decay'])\n",
        "trainer.scheduler = optim.lr_scheduler.CosineAnnealingLR(trainer.optimizer, T_max=config['training']['epochs'])\n",
        "```\n",
        "\n",
        "We also provide a utility function to create your own optimizer and scheduler with the congig and some extra bells and whistles. You are free to use it or not. Do read their code and documentation to understand how it works (`hw4lib/utils/*`).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WStK_vNzzQRq"
      },
      "source": [
        "#### Setting up the optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "GkljGtIPkATt"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ðŸ”§ Configuring Optimizer:\n",
            "â”œâ”€â”€ Type: ADAM\n",
            "â”œâ”€â”€ Base LR: 0.0003\n",
            "â”œâ”€â”€ Weight Decay: 0.0001\n",
            "â”œâ”€â”€ Parameter Groups:\n",
            "â”‚   â”œâ”€â”€ Group: self_attn\n",
            "â”‚   â”‚   â”œâ”€â”€ LR: 0.0001\n",
            "â”‚   â”‚   â””â”€â”€ Patterns: []\n",
            "â”‚   â”œâ”€â”€ Group: ffn\n",
            "â”‚   â”‚   â”œâ”€â”€ LR: 0.0001\n",
            "â”‚   â”‚   â””â”€â”€ Patterns: []\n",
            "â”‚   â””â”€â”€ Default Group (unmatched parameters)\n",
            "â””â”€â”€ Adam Specific:\n",
            "    â”œâ”€â”€ Betas: [0.9, 0.999]\n",
            "    â”œâ”€â”€ Epsilon: 1e-08\n",
            "    â””â”€â”€ AMSGrad: False\n"
          ]
        }
      ],
      "source": [
        "trainer.optimizer = create_optimizer(\n",
        "    model=model,\n",
        "    opt_config=config['optimizer']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5Luh4WzzQRq"
      },
      "source": [
        "#### Creating a test scheduler and plotting the learning rate schedule"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "inatJGBVi3II"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ðŸ“ˆ Configuring Learning Rate Scheduler:\n",
            "â”œâ”€â”€ Type: COSINE\n",
            "â”œâ”€â”€ Cosine Annealing Settings:\n",
            "â”‚   â”œâ”€â”€ T_max: 50 epochs (150 steps)\n",
            "â”‚   â””â”€â”€ Min LR: 1e-08\n",
            "â”œâ”€â”€ Warmup Settings:\n",
            "â”‚   â”œâ”€â”€ Duration: 5 epochs (15 steps)\n",
            "â”‚   â”œâ”€â”€ Start Factor: 0.1\n",
            "â”‚   â””â”€â”€ End Factor: 1.0\n",
            "Warning: Only showing 5 out of 61 parameter groups for clarity\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/agcheria/miniconda3/envs/hw4/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:240: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x400 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "test_scheduler = create_scheduler(\n",
        "    optimizer=trainer.optimizer,\n",
        "    scheduler_config=config['scheduler'],\n",
        "    train_loader=train_loader,\n",
        "    gradient_accumulation_steps=config['training']['gradient_accumulation_steps']\n",
        ")\n",
        "\n",
        "plot_lr_schedule(\n",
        "    scheduler=test_scheduler,\n",
        "    num_epochs=config['training']['epochs'],\n",
        "    train_loader=train_loader,\n",
        "    gradient_accumulation_steps=config['training']['gradient_accumulation_steps']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AxafmUnzQRq"
      },
      "source": [
        "#### Setting up the scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "yXrwTbqdiPE_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ðŸ“ˆ Configuring Learning Rate Scheduler:\n",
            "â”œâ”€â”€ Type: COSINE\n",
            "â”œâ”€â”€ Cosine Annealing Settings:\n",
            "â”‚   â”œâ”€â”€ T_max: 50 epochs (150 steps)\n",
            "â”‚   â””â”€â”€ Min LR: 1e-08\n",
            "â”œâ”€â”€ Warmup Settings:\n",
            "â”‚   â”œâ”€â”€ Duration: 5 epochs (15 steps)\n",
            "â”‚   â”œâ”€â”€ Start Factor: 0.1\n",
            "â”‚   â””â”€â”€ End Factor: 1.0\n"
          ]
        }
      ],
      "source": [
        "trainer.scheduler = create_scheduler(\n",
        "    optimizer=trainer.optimizer,\n",
        "    scheduler_config=config['scheduler'],\n",
        "    train_loader=train_loader,\n",
        "    gradient_accumulation_steps=config['training']['gradient_accumulation_steps']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XI0dHJB7Q68"
      },
      "source": [
        "# Train\n",
        "- Set your epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "nugAKoOw7Q68"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/3 [00:00<?, ?it/s]/home/agcheria/idl_assignment_Fall_2025/HW4/HW4P1/IDL-HW4/IDL-HW4/hw4lib/trainers/lm_trainer.py:89: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=use_amp):\n",
            "                                                                                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "ðŸ“Š Metrics (Epoch 0):\n",
            "â”œâ”€â”€ TRAIN:\n",
            "â”‚   â”œâ”€â”€ ce_loss_char: 2.0896\n",
            "â”‚   â”œâ”€â”€ ce_loss_token: 8.6461\n",
            "â”‚   â”œâ”€â”€ perplexity_char: 8.0813\n",
            "â”‚   â””â”€â”€ perplexity_token: 5687.9697\n",
            "â””â”€â”€ VAL:\n",
            "    â”œâ”€â”€ ce_loss_char: 2.1443\n",
            "    â”œâ”€â”€ ce_loss_token: 8.4715\n",
            "    â”œâ”€â”€ perplexity_char: 8.5359\n",
            "    â””â”€â”€ perplexity_token: 4776.8501\n",
            "â””â”€â”€ TRAINING:\n",
            "    â””â”€â”€ learning_rate: 0.000084\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/3 [00:00<?, ?it/s]/home/agcheria/idl_assignment_Fall_2025/HW4/HW4P1/IDL-HW4/IDL-HW4/hw4lib/trainers/lm_trainer.py:89: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=use_amp):\n",
            "                                                                                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "ðŸ“Š Metrics (Epoch 1):\n",
            "â”œâ”€â”€ TRAIN:\n",
            "â”‚   â”œâ”€â”€ ce_loss_char: 2.0238\n",
            "â”‚   â”œâ”€â”€ ce_loss_token: 8.3739\n",
            "â”‚   â”œâ”€â”€ perplexity_char: 7.5668\n",
            "â”‚   â””â”€â”€ perplexity_token: 4332.4854\n",
            "â””â”€â”€ VAL:\n",
            "    â”œâ”€â”€ ce_loss_char: 2.0558\n",
            "    â”œâ”€â”€ ce_loss_token: 8.1219\n",
            "    â”œâ”€â”€ perplexity_char: 7.8129\n",
            "    â””â”€â”€ perplexity_token: 3367.3762\n",
            "â””â”€â”€ TRAINING:\n",
            "    â””â”€â”€ learning_rate: 0.000138\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/3 [00:00<?, ?it/s]/home/agcheria/idl_assignment_Fall_2025/HW4/HW4P1/IDL-HW4/IDL-HW4/hw4lib/trainers/lm_trainer.py:89: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=use_amp):\n",
            "                                                                                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "ðŸ“Š Metrics (Epoch 2):\n",
            "â”œâ”€â”€ TRAIN:\n",
            "â”‚   â”œâ”€â”€ ce_loss_char: 1.9258\n",
            "â”‚   â”œâ”€â”€ ce_loss_token: 7.9687\n",
            "â”‚   â”œâ”€â”€ perplexity_char: 6.8608\n",
            "â”‚   â””â”€â”€ perplexity_token: 2888.9666\n",
            "â””â”€â”€ VAL:\n",
            "    â”œâ”€â”€ ce_loss_char: 1.9762\n",
            "    â”œâ”€â”€ ce_loss_token: 7.8076\n",
            "    â”œâ”€â”€ perplexity_char: 7.2155\n",
            "    â””â”€â”€ perplexity_token: 2459.2739\n",
            "â””â”€â”€ TRAINING:\n",
            "    â””â”€â”€ learning_rate: 0.000192\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/3 [00:00<?, ?it/s]/home/agcheria/idl_assignment_Fall_2025/HW4/HW4P1/IDL-HW4/IDL-HW4/hw4lib/trainers/lm_trainer.py:89: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=use_amp):\n",
            "                                                                                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "ðŸ“Š Metrics (Epoch 3):\n",
            "â”œâ”€â”€ TRAIN:\n",
            "â”‚   â”œâ”€â”€ ce_loss_char: 1.8387\n",
            "â”‚   â”œâ”€â”€ ce_loss_token: 7.6082\n",
            "â”‚   â”œâ”€â”€ perplexity_char: 6.2884\n",
            "â”‚   â””â”€â”€ perplexity_token: 2014.5862\n",
            "â””â”€â”€ VAL:\n",
            "    â”œâ”€â”€ ce_loss_char: 1.9075\n",
            "    â”œâ”€â”€ ce_loss_token: 7.5362\n",
            "    â”œâ”€â”€ perplexity_char: 6.7364\n",
            "    â””â”€â”€ perplexity_token: 1874.6454\n",
            "â””â”€â”€ TRAINING:\n",
            "    â””â”€â”€ learning_rate: 0.000246\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/3 [00:00<?, ?it/s]/home/agcheria/idl_assignment_Fall_2025/HW4/HW4P1/IDL-HW4/IDL-HW4/hw4lib/trainers/lm_trainer.py:89: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=use_amp):\n",
            "[Training LM]:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  7.78it/s, acc_step=1/1, ce_loss_token=7.3181, perplexity_token=1507.3724]/home/agcheria/miniconda3/envs/hw4/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:240: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
            "                                                                                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "ðŸ“Š Metrics (Epoch 4):\n",
            "â”œâ”€â”€ TRAIN:\n",
            "â”‚   â”œâ”€â”€ ce_loss_char: 1.7669\n",
            "â”‚   â”œâ”€â”€ ce_loss_token: 7.3109\n",
            "â”‚   â”œâ”€â”€ perplexity_char: 5.8524\n",
            "â”‚   â””â”€â”€ perplexity_token: 1496.4774\n",
            "â””â”€â”€ VAL:\n",
            "    â”œâ”€â”€ ce_loss_char: 1.8462\n",
            "    â”œâ”€â”€ ce_loss_token: 7.2940\n",
            "    â”œâ”€â”€ perplexity_char: 6.3358\n",
            "    â””â”€â”€ perplexity_token: 1471.3903\n",
            "â””â”€â”€ TRAINING:\n",
            "    â””â”€â”€ learning_rate: 0.000300\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/3 [00:00<?, ?it/s]/home/agcheria/idl_assignment_Fall_2025/HW4/HW4P1/IDL-HW4/IDL-HW4/hw4lib/trainers/lm_trainer.py:89: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=use_amp):\n",
            "                                                                                                                            \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "ðŸ“Š Metrics (Epoch 5):\n",
            "â”œâ”€â”€ TRAIN:\n",
            "â”‚   â”œâ”€â”€ ce_loss_char: 1.7025\n",
            "â”‚   â”œâ”€â”€ ce_loss_token: 7.0447\n",
            "â”‚   â”œâ”€â”€ perplexity_char: 5.4879\n",
            "â”‚   â””â”€â”€ perplexity_token: 1146.7944\n",
            "â””â”€â”€ VAL:\n",
            "    â”œâ”€â”€ ce_loss_char: 1.7970\n",
            "    â”œâ”€â”€ ce_loss_token: 7.0996\n",
            "    â”œâ”€â”€ perplexity_char: 6.0317\n",
            "    â””â”€â”€ perplexity_token: 1211.5266\n",
            "â””â”€â”€ TRAINING:\n",
            "    â””â”€â”€ learning_rate: 0.000300\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/3 [00:00<?, ?it/s]/home/agcheria/idl_assignment_Fall_2025/HW4/HW4P1/IDL-HW4/IDL-HW4/hw4lib/trainers/lm_trainer.py:89: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=use_amp):\n",
            "                                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "ðŸ“Š Metrics (Epoch 6):\n",
            "â”œâ”€â”€ TRAIN:\n",
            "â”‚   â”œâ”€â”€ ce_loss_char: 1.6496\n",
            "â”‚   â”œâ”€â”€ ce_loss_token: 6.8258\n",
            "â”‚   â”œâ”€â”€ perplexity_char: 5.2050\n",
            "â”‚   â””â”€â”€ perplexity_token: 921.2969\n",
            "â””â”€â”€ VAL:\n",
            "    â”œâ”€â”€ ce_loss_char: 1.7661\n",
            "    â”œâ”€â”€ ce_loss_token: 6.9774\n",
            "    â”œâ”€â”€ perplexity_char: 5.8479\n",
            "    â””â”€â”€ perplexity_token: 1072.0918\n",
            "â””â”€â”€ TRAINING:\n",
            "    â””â”€â”€ learning_rate: 0.000299\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/3 [00:00<?, ?it/s]/home/agcheria/idl_assignment_Fall_2025/HW4/HW4P1/IDL-HW4/IDL-HW4/hw4lib/trainers/lm_trainer.py:89: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=use_amp):\n",
            "                                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "ðŸ“Š Metrics (Epoch 7):\n",
            "â”œâ”€â”€ TRAIN:\n",
            "â”‚   â”œâ”€â”€ ce_loss_char: 1.6135\n",
            "â”‚   â”œâ”€â”€ ce_loss_token: 6.6761\n",
            "â”‚   â”œâ”€â”€ perplexity_char: 5.0201\n",
            "â”‚   â””â”€â”€ perplexity_token: 793.2386\n",
            "â””â”€â”€ VAL:\n",
            "    â”œâ”€â”€ ce_loss_char: 1.7488\n",
            "    â”œâ”€â”€ ce_loss_token: 6.9091\n",
            "    â”œâ”€â”€ perplexity_char: 5.7476\n",
            "    â””â”€â”€ perplexity_token: 1001.3123\n",
            "â””â”€â”€ TRAINING:\n",
            "    â””â”€â”€ learning_rate: 0.000297\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/3 [00:00<?, ?it/s]/home/agcheria/idl_assignment_Fall_2025/HW4/HW4P1/IDL-HW4/IDL-HW4/hw4lib/trainers/lm_trainer.py:89: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=use_amp):\n",
            "                                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "ðŸ“Š Metrics (Epoch 8):\n",
            "â”œâ”€â”€ TRAIN:\n",
            "â”‚   â”œâ”€â”€ ce_loss_char: 1.5888\n",
            "â”‚   â”œâ”€â”€ ce_loss_token: 6.5741\n",
            "â”‚   â”œâ”€â”€ perplexity_char: 4.8978\n",
            "â”‚   â””â”€â”€ perplexity_token: 716.2662\n",
            "â””â”€â”€ VAL:\n",
            "    â”œâ”€â”€ ce_loss_char: 1.7382\n",
            "    â”œâ”€â”€ ce_loss_token: 6.8674\n",
            "    â”œâ”€â”€ perplexity_char: 5.6873\n",
            "    â””â”€â”€ perplexity_token: 960.4406\n",
            "â””â”€â”€ TRAINING:\n",
            "    â””â”€â”€ learning_rate: 0.000295\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/3 [00:00<?, ?it/s]/home/agcheria/idl_assignment_Fall_2025/HW4/HW4P1/IDL-HW4/IDL-HW4/hw4lib/trainers/lm_trainer.py:89: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=use_amp):\n",
            "                                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "ðŸ“Š Metrics (Epoch 9):\n",
            "â”œâ”€â”€ TRAIN:\n",
            "â”‚   â”œâ”€â”€ ce_loss_char: 1.5704\n",
            "â”‚   â”œâ”€â”€ ce_loss_token: 6.4981\n",
            "â”‚   â”œâ”€â”€ perplexity_char: 4.8088\n",
            "â”‚   â””â”€â”€ perplexity_token: 663.8941\n",
            "â””â”€â”€ VAL:\n",
            "    â”œâ”€â”€ ce_loss_char: 1.7313\n",
            "    â”œâ”€â”€ ce_loss_token: 6.8398\n",
            "    â”œâ”€â”€ perplexity_char: 5.6478\n",
            "    â””â”€â”€ perplexity_token: 934.3066\n",
            "â””â”€â”€ TRAINING:\n",
            "    â””â”€â”€ learning_rate: 0.000293\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/3 [00:00<?, ?it/s]/home/agcheria/idl_assignment_Fall_2025/HW4/HW4P1/IDL-HW4/IDL-HW4/hw4lib/trainers/lm_trainer.py:89: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=use_amp):\n",
            "                                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "ðŸ“Š Metrics (Epoch 10):\n",
            "â”œâ”€â”€ TRAIN:\n",
            "â”‚   â”œâ”€â”€ ce_loss_char: 1.5538\n",
            "â”‚   â”œâ”€â”€ ce_loss_token: 6.4295\n",
            "â”‚   â”œâ”€â”€ perplexity_char: 4.7296\n",
            "â”‚   â””â”€â”€ perplexity_token: 619.8386\n",
            "â””â”€â”€ VAL:\n",
            "    â”œâ”€â”€ ce_loss_char: 1.7214\n",
            "    â”œâ”€â”€ ce_loss_token: 6.8008\n",
            "    â”œâ”€â”€ perplexity_char: 5.5923\n",
            "    â””â”€â”€ perplexity_token: 898.5743\n",
            "â””â”€â”€ TRAINING:\n",
            "    â””â”€â”€ learning_rate: 0.000289\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/3 [00:00<?, ?it/s]/home/agcheria/idl_assignment_Fall_2025/HW4/HW4P1/IDL-HW4/IDL-HW4/hw4lib/trainers/lm_trainer.py:89: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=use_amp):\n",
            "                                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "ðŸ“Š Metrics (Epoch 11):\n",
            "â”œâ”€â”€ TRAIN:\n",
            "â”‚   â”œâ”€â”€ ce_loss_char: 1.5342\n",
            "â”‚   â”œâ”€â”€ ce_loss_token: 6.3482\n",
            "â”‚   â”œâ”€â”€ perplexity_char: 4.6377\n",
            "â”‚   â””â”€â”€ perplexity_token: 571.4756\n",
            "â””â”€â”€ VAL:\n",
            "    â”œâ”€â”€ ce_loss_char: 1.7078\n",
            "    â”œâ”€â”€ ce_loss_token: 6.7473\n",
            "    â”œâ”€â”€ perplexity_char: 5.5170\n",
            "    â””â”€â”€ perplexity_token: 851.7349\n",
            "â””â”€â”€ TRAINING:\n",
            "    â””â”€â”€ learning_rate: 0.000286\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/3 [00:00<?, ?it/s]/home/agcheria/idl_assignment_Fall_2025/HW4/HW4P1/IDL-HW4/IDL-HW4/hw4lib/trainers/lm_trainer.py:89: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=use_amp):\n",
            "                                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "ðŸ“Š Metrics (Epoch 12):\n",
            "â”œâ”€â”€ TRAIN:\n",
            "â”‚   â”œâ”€â”€ ce_loss_char: 1.5110\n",
            "â”‚   â”œâ”€â”€ ce_loss_token: 6.2523\n",
            "â”‚   â”œâ”€â”€ perplexity_char: 4.5314\n",
            "â”‚   â””â”€â”€ perplexity_token: 519.2206\n",
            "â””â”€â”€ VAL:\n",
            "    â”œâ”€â”€ ce_loss_char: 1.7000\n",
            "    â”œâ”€â”€ ce_loss_token: 6.7162\n",
            "    â”œâ”€â”€ perplexity_char: 5.4739\n",
            "    â””â”€â”€ perplexity_token: 825.7109\n",
            "â””â”€â”€ TRAINING:\n",
            "    â””â”€â”€ learning_rate: 0.000281\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/3 [00:00<?, ?it/s]/home/agcheria/idl_assignment_Fall_2025/HW4/HW4P1/IDL-HW4/IDL-HW4/hw4lib/trainers/lm_trainer.py:89: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=use_amp):\n",
            "                                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "ðŸ“Š Metrics (Epoch 13):\n",
            "â”œâ”€â”€ TRAIN:\n",
            "â”‚   â”œâ”€â”€ ce_loss_char: 1.4845\n",
            "â”‚   â”œâ”€â”€ ce_loss_token: 6.1427\n",
            "â”‚   â”œâ”€â”€ perplexity_char: 4.4129\n",
            "â”‚   â””â”€â”€ perplexity_token: 465.2888\n",
            "â””â”€â”€ VAL:\n",
            "    â”œâ”€â”€ ce_loss_char: 1.6902\n",
            "    â”œâ”€â”€ ce_loss_token: 6.6775\n",
            "    â”œâ”€â”€ perplexity_char: 5.4205\n",
            "    â””â”€â”€ perplexity_token: 794.3370\n",
            "â””â”€â”€ TRAINING:\n",
            "    â””â”€â”€ learning_rate: 0.000277\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/3 [00:00<?, ?it/s]/home/agcheria/idl_assignment_Fall_2025/HW4/HW4P1/IDL-HW4/IDL-HW4/hw4lib/trainers/lm_trainer.py:89: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=use_amp):\n",
            "                                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "ðŸ“Š Metrics (Epoch 14):\n",
            "â”œâ”€â”€ TRAIN:\n",
            "â”‚   â”œâ”€â”€ ce_loss_char: 1.4574\n",
            "â”‚   â”œâ”€â”€ ce_loss_token: 6.0305\n",
            "â”‚   â”œâ”€â”€ perplexity_char: 4.2949\n",
            "â”‚   â””â”€â”€ perplexity_token: 415.9192\n",
            "â””â”€â”€ VAL:\n",
            "    â”œâ”€â”€ ce_loss_char: 1.6812\n",
            "    â”œâ”€â”€ ce_loss_token: 6.6422\n",
            "    â”œâ”€â”€ perplexity_char: 5.3722\n",
            "    â””â”€â”€ perplexity_token: 766.7728\n",
            "â””â”€â”€ TRAINING:\n",
            "    â””â”€â”€ learning_rate: 0.000271\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/3 [00:00<?, ?it/s]/home/agcheria/idl_assignment_Fall_2025/HW4/HW4P1/IDL-HW4/IDL-HW4/hw4lib/trainers/lm_trainer.py:89: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=use_amp):\n",
            "                                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "ðŸ“Š Metrics (Epoch 15):\n",
            "â”œâ”€â”€ TRAIN:\n",
            "â”‚   â”œâ”€â”€ ce_loss_char: 1.4324\n",
            "â”‚   â”œâ”€â”€ ce_loss_token: 5.9270\n",
            "â”‚   â”œâ”€â”€ perplexity_char: 4.1887\n",
            "â”‚   â””â”€â”€ perplexity_token: 375.0095\n",
            "â””â”€â”€ VAL:\n",
            "    â”œâ”€â”€ ce_loss_char: 1.6763\n",
            "    â”œâ”€â”€ ce_loss_token: 6.6225\n",
            "    â”œâ”€â”€ perplexity_char: 5.3455\n",
            "    â””â”€â”€ perplexity_token: 751.8137\n",
            "â””â”€â”€ TRAINING:\n",
            "    â””â”€â”€ learning_rate: 0.000266\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/3 [00:00<?, ?it/s]/home/agcheria/idl_assignment_Fall_2025/HW4/HW4P1/IDL-HW4/IDL-HW4/hw4lib/trainers/lm_trainer.py:89: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=use_amp):\n",
            "                                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "ðŸ“Š Metrics (Epoch 16):\n",
            "â”œâ”€â”€ TRAIN:\n",
            "â”‚   â”œâ”€â”€ ce_loss_char: 1.4085\n",
            "â”‚   â”œâ”€â”€ ce_loss_token: 5.8282\n",
            "â”‚   â”œâ”€â”€ perplexity_char: 4.0900\n",
            "â”‚   â””â”€â”€ perplexity_token: 339.7587\n",
            "â””â”€â”€ VAL:\n",
            "    â”œâ”€â”€ ce_loss_char: 1.6697\n",
            "    â”œâ”€â”€ ce_loss_token: 6.5965\n",
            "    â”œâ”€â”€ perplexity_char: 5.3104\n",
            "    â””â”€â”€ perplexity_token: 732.5062\n",
            "â””â”€â”€ TRAINING:\n",
            "    â””â”€â”€ learning_rate: 0.000259\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/3 [00:00<?, ?it/s]/home/agcheria/idl_assignment_Fall_2025/HW4/HW4P1/IDL-HW4/IDL-HW4/hw4lib/trainers/lm_trainer.py:89: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=use_amp):\n",
            "                                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "ðŸ“Š Metrics (Epoch 17):\n",
            "â”œâ”€â”€ TRAIN:\n",
            "â”‚   â”œâ”€â”€ ce_loss_char: 1.3855\n",
            "â”‚   â”œâ”€â”€ ce_loss_token: 5.7328\n",
            "â”‚   â”œâ”€â”€ perplexity_char: 3.9967\n",
            "â”‚   â””â”€â”€ perplexity_token: 308.8303\n",
            "â””â”€â”€ VAL:\n",
            "    â”œâ”€â”€ ce_loss_char: 1.6638\n",
            "    â”œâ”€â”€ ce_loss_token: 6.5732\n",
            "    â”œâ”€â”€ perplexity_char: 5.2792\n",
            "    â””â”€â”€ perplexity_token: 715.6639\n",
            "â””â”€â”€ TRAINING:\n",
            "    â””â”€â”€ learning_rate: 0.000253\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/3 [00:00<?, ?it/s]/home/agcheria/idl_assignment_Fall_2025/HW4/HW4P1/IDL-HW4/IDL-HW4/hw4lib/trainers/lm_trainer.py:89: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=use_amp):\n",
            "                                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "ðŸ“Š Metrics (Epoch 18):\n",
            "â”œâ”€â”€ TRAIN:\n",
            "â”‚   â”œâ”€â”€ ce_loss_char: 1.3626\n",
            "â”‚   â”œâ”€â”€ ce_loss_token: 5.6382\n",
            "â”‚   â”œâ”€â”€ perplexity_char: 3.9064\n",
            "â”‚   â””â”€â”€ perplexity_token: 280.9691\n",
            "â””â”€â”€ VAL:\n",
            "    â”œâ”€â”€ ce_loss_char: 1.6566\n",
            "    â”œâ”€â”€ ce_loss_token: 6.5448\n",
            "    â”œâ”€â”€ perplexity_char: 5.2413\n",
            "    â””â”€â”€ perplexity_token: 695.5902\n",
            "â””â”€â”€ TRAINING:\n",
            "    â””â”€â”€ learning_rate: 0.000246\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/3 [00:00<?, ?it/s]/home/agcheria/idl_assignment_Fall_2025/HW4/HW4P1/IDL-HW4/IDL-HW4/hw4lib/trainers/lm_trainer.py:89: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=use_amp):\n",
            "                                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "ðŸ“Š Metrics (Epoch 19):\n",
            "â”œâ”€â”€ TRAIN:\n",
            "â”‚   â”œâ”€â”€ ce_loss_char: 1.3381\n",
            "â”‚   â”œâ”€â”€ ce_loss_token: 5.5368\n",
            "â”‚   â”œâ”€â”€ perplexity_char: 3.8118\n",
            "â”‚   â””â”€â”€ perplexity_token: 253.8652\n",
            "â””â”€â”€ VAL:\n",
            "    â”œâ”€â”€ ce_loss_char: 1.6504\n",
            "    â”œâ”€â”€ ce_loss_token: 6.5205\n",
            "    â”œâ”€â”€ perplexity_char: 5.2092\n",
            "    â””â”€â”€ perplexity_token: 678.9026\n",
            "â””â”€â”€ TRAINING:\n",
            "    â””â”€â”€ learning_rate: 0.000238\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/3 [00:00<?, ?it/s]/home/agcheria/idl_assignment_Fall_2025/HW4/HW4P1/IDL-HW4/IDL-HW4/hw4lib/trainers/lm_trainer.py:89: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=use_amp):\n",
            "                                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "ðŸ“Š Metrics (Epoch 20):\n",
            "â”œâ”€â”€ TRAIN:\n",
            "â”‚   â”œâ”€â”€ ce_loss_char: 1.3148\n",
            "â”‚   â”œâ”€â”€ ce_loss_token: 5.4402\n",
            "â”‚   â”œâ”€â”€ perplexity_char: 3.7239\n",
            "â”‚   â””â”€â”€ perplexity_token: 230.4885\n",
            "â””â”€â”€ VAL:\n",
            "    â”œâ”€â”€ ce_loss_char: 1.6418\n",
            "    â”œâ”€â”€ ce_loss_token: 6.4862\n",
            "    â”œâ”€â”€ perplexity_char: 5.1642\n",
            "    â””â”€â”€ perplexity_token: 656.0215\n",
            "â””â”€â”€ TRAINING:\n",
            "    â””â”€â”€ learning_rate: 0.000230\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/3 [00:00<?, ?it/s]/home/agcheria/idl_assignment_Fall_2025/HW4/HW4P1/IDL-HW4/IDL-HW4/hw4lib/trainers/lm_trainer.py:89: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=use_amp):\n",
            "                                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "ðŸ“Š Metrics (Epoch 21):\n",
            "â”œâ”€â”€ TRAIN:\n",
            "â”‚   â”œâ”€â”€ ce_loss_char: 1.2921\n",
            "â”‚   â”œâ”€â”€ ce_loss_token: 5.3463\n",
            "â”‚   â”œâ”€â”€ perplexity_char: 3.6403\n",
            "â”‚   â””â”€â”€ perplexity_token: 209.8375\n",
            "â””â”€â”€ VAL:\n",
            "    â”œâ”€â”€ ce_loss_char: 1.6320\n",
            "    â”œâ”€â”€ ce_loss_token: 6.4475\n",
            "    â”œâ”€â”€ perplexity_char: 5.1139\n",
            "    â””â”€â”€ perplexity_token: 631.1088\n",
            "â””â”€â”€ TRAINING:\n",
            "    â””â”€â”€ learning_rate: 0.000222\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/3 [00:00<?, ?it/s]/home/agcheria/idl_assignment_Fall_2025/HW4/HW4P1/IDL-HW4/IDL-HW4/hw4lib/trainers/lm_trainer.py:89: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=use_amp):\n",
            "                                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "ðŸ“Š Metrics (Epoch 22):\n",
            "â”œâ”€â”€ TRAIN:\n",
            "â”‚   â”œâ”€â”€ ce_loss_char: 1.2682\n",
            "â”‚   â”œâ”€â”€ ce_loss_token: 5.2474\n",
            "â”‚   â”œâ”€â”€ perplexity_char: 3.5543\n",
            "â”‚   â””â”€â”€ perplexity_token: 190.0674\n",
            "â””â”€â”€ VAL:\n",
            "    â”œâ”€â”€ ce_loss_char: 1.6284\n",
            "    â”œâ”€â”€ ce_loss_token: 6.4334\n",
            "    â”œâ”€â”€ perplexity_char: 5.0957\n",
            "    â””â”€â”€ perplexity_token: 622.2853\n",
            "â””â”€â”€ TRAINING:\n",
            "    â””â”€â”€ learning_rate: 0.000214\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/3 [00:00<?, ?it/s]/home/agcheria/idl_assignment_Fall_2025/HW4/HW4P1/IDL-HW4/IDL-HW4/hw4lib/trainers/lm_trainer.py:89: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=use_amp):\n",
            "                                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "ðŸ“Š Metrics (Epoch 23):\n",
            "â”œâ”€â”€ TRAIN:\n",
            "â”‚   â”œâ”€â”€ ce_loss_char: 1.2481\n",
            "â”‚   â”œâ”€â”€ ce_loss_token: 5.1642\n",
            "â”‚   â”œâ”€â”€ perplexity_char: 3.4836\n",
            "â”‚   â””â”€â”€ perplexity_token: 174.9001\n",
            "â””â”€â”€ VAL:\n",
            "    â”œâ”€â”€ ce_loss_char: 1.6303\n",
            "    â”œâ”€â”€ ce_loss_token: 6.4410\n",
            "    â”œâ”€â”€ perplexity_char: 5.1055\n",
            "    â””â”€â”€ perplexity_token: 627.0527\n",
            "â””â”€â”€ TRAINING:\n",
            "    â””â”€â”€ learning_rate: 0.000205\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/3 [00:00<?, ?it/s]/home/agcheria/idl_assignment_Fall_2025/HW4/HW4P1/IDL-HW4/IDL-HW4/hw4lib/trainers/lm_trainer.py:89: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=use_amp):\n",
            "                                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "ðŸ“Š Metrics (Epoch 24):\n",
            "â”œâ”€â”€ TRAIN:\n",
            "â”‚   â”œâ”€â”€ ce_loss_char: 1.2302\n",
            "â”‚   â”œâ”€â”€ ce_loss_token: 5.0903\n",
            "â”‚   â”œâ”€â”€ perplexity_char: 3.4219\n",
            "â”‚   â””â”€â”€ perplexity_token: 162.4348\n",
            "â””â”€â”€ VAL:\n",
            "    â”œâ”€â”€ ce_loss_char: 1.6249\n",
            "    â”œâ”€â”€ ce_loss_token: 6.4197\n",
            "    â”œâ”€â”€ perplexity_char: 5.0781\n",
            "    â””â”€â”€ perplexity_token: 613.8486\n",
            "â””â”€â”€ TRAINING:\n",
            "    â””â”€â”€ learning_rate: 0.000196\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/3 [00:00<?, ?it/s]/home/agcheria/idl_assignment_Fall_2025/HW4/HW4P1/IDL-HW4/IDL-HW4/hw4lib/trainers/lm_trainer.py:89: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=use_amp):\n",
            "                                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "ðŸ“Š Metrics (Epoch 25):\n",
            "â”œâ”€â”€ TRAIN:\n",
            "â”‚   â”œâ”€â”€ ce_loss_char: 1.2111\n",
            "â”‚   â”œâ”€â”€ ce_loss_token: 5.0113\n",
            "â”‚   â”œâ”€â”€ perplexity_char: 3.3572\n",
            "â”‚   â””â”€â”€ perplexity_token: 150.0925\n",
            "â””â”€â”€ VAL:\n",
            "    â”œâ”€â”€ ce_loss_char: 1.6290\n",
            "    â”œâ”€â”€ ce_loss_token: 6.4357\n",
            "    â”œâ”€â”€ perplexity_char: 5.0987\n",
            "    â””â”€â”€ perplexity_token: 623.7383\n",
            "â””â”€â”€ TRAINING:\n",
            "    â””â”€â”€ learning_rate: 0.000187\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/3 [00:00<?, ?it/s]/home/agcheria/idl_assignment_Fall_2025/HW4/HW4P1/IDL-HW4/IDL-HW4/hw4lib/trainers/lm_trainer.py:89: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=use_amp):\n",
            "                                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "ðŸ“Š Metrics (Epoch 26):\n",
            "â”œâ”€â”€ TRAIN:\n",
            "â”‚   â”œâ”€â”€ ce_loss_char: 1.1931\n",
            "â”‚   â”œâ”€â”€ ce_loss_token: 4.9369\n",
            "â”‚   â”œâ”€â”€ perplexity_char: 3.2974\n",
            "â”‚   â””â”€â”€ perplexity_token: 139.3325\n",
            "â””â”€â”€ VAL:\n",
            "    â”œâ”€â”€ ce_loss_char: 1.6228\n",
            "    â”œâ”€â”€ ce_loss_token: 6.4111\n",
            "    â”œâ”€â”€ perplexity_char: 5.0670\n",
            "    â””â”€â”€ perplexity_token: 608.5859\n",
            "â””â”€â”€ TRAINING:\n",
            "    â””â”€â”€ learning_rate: 0.000178\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/3 [00:00<?, ?it/s]/home/agcheria/idl_assignment_Fall_2025/HW4/HW4P1/IDL-HW4/IDL-HW4/hw4lib/trainers/lm_trainer.py:89: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=use_amp):\n",
            "                                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "ðŸ“Š Metrics (Epoch 27):\n",
            "â”œâ”€â”€ TRAIN:\n",
            "â”‚   â”œâ”€â”€ ce_loss_char: 1.1752\n",
            "â”‚   â”œâ”€â”€ ce_loss_token: 4.8626\n",
            "â”‚   â”œâ”€â”€ perplexity_char: 3.2387\n",
            "â”‚   â””â”€â”€ perplexity_token: 129.3566\n",
            "â””â”€â”€ VAL:\n",
            "    â”œâ”€â”€ ce_loss_char: 1.6223\n",
            "    â”œâ”€â”€ ce_loss_token: 6.4094\n",
            "    â”œâ”€â”€ perplexity_char: 5.0648\n",
            "    â””â”€â”€ perplexity_token: 607.5352\n",
            "â””â”€â”€ TRAINING:\n",
            "    â””â”€â”€ learning_rate: 0.000169\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/3 [00:00<?, ?it/s]/home/agcheria/idl_assignment_Fall_2025/HW4/HW4P1/IDL-HW4/IDL-HW4/hw4lib/trainers/lm_trainer.py:89: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=use_amp):\n",
            "                                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "ðŸ“Š Metrics (Epoch 28):\n",
            "â”œâ”€â”€ TRAIN:\n",
            "â”‚   â”œâ”€â”€ ce_loss_char: 1.1584\n",
            "â”‚   â”œâ”€â”€ ce_loss_token: 4.7932\n",
            "â”‚   â”œâ”€â”€ perplexity_char: 3.1848\n",
            "â”‚   â””â”€â”€ perplexity_token: 120.6826\n",
            "â””â”€â”€ VAL:\n",
            "    â”œâ”€â”€ ce_loss_char: 1.6164\n",
            "    â”œâ”€â”€ ce_loss_token: 6.3861\n",
            "    â”œâ”€â”€ perplexity_char: 5.0350\n",
            "    â””â”€â”€ perplexity_token: 593.5196\n",
            "â””â”€â”€ TRAINING:\n",
            "    â””â”€â”€ learning_rate: 0.000159\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/3 [00:00<?, ?it/s]/home/agcheria/idl_assignment_Fall_2025/HW4/HW4P1/IDL-HW4/IDL-HW4/hw4lib/trainers/lm_trainer.py:89: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=use_amp):\n",
            "                                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "ðŸ“Š Metrics (Epoch 29):\n",
            "â”œâ”€â”€ TRAIN:\n",
            "â”‚   â”œâ”€â”€ ce_loss_char: 1.1428\n",
            "â”‚   â”œâ”€â”€ ce_loss_token: 4.7288\n",
            "â”‚   â”œâ”€â”€ perplexity_char: 3.1356\n",
            "â”‚   â””â”€â”€ perplexity_token: 113.1588\n",
            "â””â”€â”€ VAL:\n",
            "    â”œâ”€â”€ ce_loss_char: 1.6181\n",
            "    â”œâ”€â”€ ce_loss_token: 6.3926\n",
            "    â”œâ”€â”€ perplexity_char: 5.0433\n",
            "    â””â”€â”€ perplexity_token: 597.4144\n",
            "â””â”€â”€ TRAINING:\n",
            "    â””â”€â”€ learning_rate: 0.000150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/3 [00:00<?, ?it/s]/home/agcheria/idl_assignment_Fall_2025/HW4/HW4P1/IDL-HW4/IDL-HW4/hw4lib/trainers/lm_trainer.py:89: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=use_amp):\n",
            "                                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "ðŸ“Š Metrics (Epoch 30):\n",
            "â”œâ”€â”€ TRAIN:\n",
            "â”‚   â”œâ”€â”€ ce_loss_char: 1.1290\n",
            "â”‚   â”œâ”€â”€ ce_loss_token: 4.6717\n",
            "â”‚   â”œâ”€â”€ perplexity_char: 3.0927\n",
            "â”‚   â””â”€â”€ perplexity_token: 106.8761\n",
            "â””â”€â”€ VAL:\n",
            "    â”œâ”€â”€ ce_loss_char: 1.6177\n",
            "    â”œâ”€â”€ ce_loss_token: 6.3910\n",
            "    â”œâ”€â”€ perplexity_char: 5.0413\n",
            "    â””â”€â”€ perplexity_token: 596.4765\n",
            "â””â”€â”€ TRAINING:\n",
            "    â””â”€â”€ learning_rate: 0.000141\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/3 [00:00<?, ?it/s]/home/agcheria/idl_assignment_Fall_2025/HW4/HW4P1/IDL-HW4/IDL-HW4/hw4lib/trainers/lm_trainer.py:89: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=use_amp):\n",
            "                                                                                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "ðŸ“Š Metrics (Epoch 31):\n",
            "â”œâ”€â”€ TRAIN:\n",
            "â”‚   â”œâ”€â”€ ce_loss_char: 1.1152\n",
            "â”‚   â”œâ”€â”€ ce_loss_token: 4.6144\n",
            "â”‚   â”œâ”€â”€ perplexity_char: 3.0501\n",
            "â”‚   â””â”€â”€ perplexity_token: 100.9229\n",
            "â””â”€â”€ VAL:\n",
            "    â”œâ”€â”€ ce_loss_char: 1.6185\n",
            "    â”œâ”€â”€ ce_loss_token: 6.3942\n",
            "    â”œâ”€â”€ perplexity_char: 5.0453\n",
            "    â””â”€â”€ perplexity_token: 598.3378\n",
            "â””â”€â”€ TRAINING:\n",
            "    â””â”€â”€ learning_rate: 0.000131\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/3 [00:00<?, ?it/s]/home/agcheria/idl_assignment_Fall_2025/HW4/HW4P1/IDL-HW4/IDL-HW4/hw4lib/trainers/lm_trainer.py:89: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=use_amp):\n",
            "                                                                                                                          \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "ðŸ“Š Metrics (Epoch 32):\n",
            "â”œâ”€â”€ TRAIN:\n",
            "â”‚   â”œâ”€â”€ ce_loss_char: 1.1034\n",
            "â”‚   â”œâ”€â”€ ce_loss_token: 4.5658\n",
            "â”‚   â”œâ”€â”€ perplexity_char: 3.0145\n",
            "â”‚   â””â”€â”€ perplexity_token: 96.1395\n",
            "â””â”€â”€ VAL:\n",
            "    â”œâ”€â”€ ce_loss_char: 1.6180\n",
            "    â”œâ”€â”€ ce_loss_token: 6.3922\n",
            "    â”œâ”€â”€ perplexity_char: 5.0428\n",
            "    â””â”€â”€ perplexity_token: 597.1550\n",
            "â””â”€â”€ TRAINING:\n",
            "    â””â”€â”€ learning_rate: 0.000122\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/3 [00:00<?, ?it/s]/home/agcheria/idl_assignment_Fall_2025/HW4/HW4P1/IDL-HW4/IDL-HW4/hw4lib/trainers/lm_trainer.py:89: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=use_amp):\n",
            "                                                                                                                          \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "ðŸ“Š Metrics (Epoch 33):\n",
            "â”œâ”€â”€ TRAIN:\n",
            "â”‚   â”œâ”€â”€ ce_loss_char: 1.0940\n",
            "â”‚   â”œâ”€â”€ ce_loss_token: 4.5266\n",
            "â”‚   â”œâ”€â”€ perplexity_char: 2.9861\n",
            "â”‚   â””â”€â”€ perplexity_token: 92.4470\n",
            "â””â”€â”€ VAL:\n",
            "    â”œâ”€â”€ ce_loss_char: 1.6174\n",
            "    â”œâ”€â”€ ce_loss_token: 6.3899\n",
            "    â”œâ”€â”€ perplexity_char: 5.0399\n",
            "    â””â”€â”€ perplexity_token: 595.8207\n",
            "â””â”€â”€ TRAINING:\n",
            "    â””â”€â”€ learning_rate: 0.000113\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/3 [00:00<?, ?it/s]/home/agcheria/idl_assignment_Fall_2025/HW4/HW4P1/IDL-HW4/IDL-HW4/hw4lib/trainers/lm_trainer.py:89: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=use_amp):\n",
            "                                                                                                                          \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "ðŸ“Š Metrics (Epoch 34):\n",
            "â”œâ”€â”€ TRAIN:\n",
            "â”‚   â”œâ”€â”€ ce_loss_char: 1.0836\n",
            "â”‚   â”œâ”€â”€ ce_loss_token: 4.4836\n",
            "â”‚   â”œâ”€â”€ perplexity_char: 2.9553\n",
            "â”‚   â””â”€â”€ perplexity_token: 88.5561\n",
            "â””â”€â”€ VAL:\n",
            "    â”œâ”€â”€ ce_loss_char: 1.6184\n",
            "    â”œâ”€â”€ ce_loss_token: 6.3938\n",
            "    â”œâ”€â”€ perplexity_char: 5.0449\n",
            "    â””â”€â”€ perplexity_token: 598.1333\n",
            "â””â”€â”€ TRAINING:\n",
            "    â””â”€â”€ learning_rate: 0.000104\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/3 [00:00<?, ?it/s]/home/agcheria/idl_assignment_Fall_2025/HW4/HW4P1/IDL-HW4/IDL-HW4/hw4lib/trainers/lm_trainer.py:89: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=use_amp):\n",
            "                                                                                                                          \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "ðŸ“Š Metrics (Epoch 35):\n",
            "â”œâ”€â”€ TRAIN:\n",
            "â”‚   â”œâ”€â”€ ce_loss_char: 1.0734\n",
            "â”‚   â”œâ”€â”€ ce_loss_token: 4.4414\n",
            "â”‚   â”œâ”€â”€ perplexity_char: 2.9252\n",
            "â”‚   â””â”€â”€ perplexity_token: 84.8916\n",
            "â””â”€â”€ VAL:\n",
            "    â”œâ”€â”€ ce_loss_char: 1.6195\n",
            "    â”œâ”€â”€ ce_loss_token: 6.3981\n",
            "    â”œâ”€â”€ perplexity_char: 5.0503\n",
            "    â””â”€â”€ perplexity_token: 600.7003\n",
            "â””â”€â”€ TRAINING:\n",
            "    â””â”€â”€ learning_rate: 0.000095\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/3 [00:00<?, ?it/s]/home/agcheria/idl_assignment_Fall_2025/HW4/HW4P1/IDL-HW4/IDL-HW4/hw4lib/trainers/lm_trainer.py:89: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=use_amp):\n",
            "                                                                                                                          \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "ðŸ“Š Metrics (Epoch 36):\n",
            "â”œâ”€â”€ TRAIN:\n",
            "â”‚   â”œâ”€â”€ ce_loss_char: 1.0652\n",
            "â”‚   â”œâ”€â”€ ce_loss_token: 4.4074\n",
            "â”‚   â”œâ”€â”€ perplexity_char: 2.9013\n",
            "â”‚   â””â”€â”€ perplexity_token: 82.0555\n",
            "â””â”€â”€ VAL:\n",
            "    â”œâ”€â”€ ce_loss_char: 1.6157\n",
            "    â”œâ”€â”€ ce_loss_token: 6.3833\n",
            "    â”œâ”€â”€ perplexity_char: 5.0315\n",
            "    â””â”€â”€ perplexity_token: 591.8940\n",
            "â””â”€â”€ TRAINING:\n",
            "    â””â”€â”€ learning_rate: 0.000086\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/3 [00:00<?, ?it/s]/home/agcheria/idl_assignment_Fall_2025/HW4/HW4P1/IDL-HW4/IDL-HW4/hw4lib/trainers/lm_trainer.py:89: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=use_amp):\n",
            "                                                                                                                          \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "ðŸ“Š Metrics (Epoch 37):\n",
            "â”œâ”€â”€ TRAIN:\n",
            "â”‚   â”œâ”€â”€ ce_loss_char: 1.0561\n",
            "â”‚   â”œâ”€â”€ ce_loss_token: 4.3700\n",
            "â”‚   â”œâ”€â”€ perplexity_char: 2.8752\n",
            "â”‚   â””â”€â”€ perplexity_token: 79.0425\n",
            "â””â”€â”€ VAL:\n",
            "    â”œâ”€â”€ ce_loss_char: 1.6123\n",
            "    â”œâ”€â”€ ce_loss_token: 6.3698\n",
            "    â”œâ”€â”€ perplexity_char: 5.0143\n",
            "    â””â”€â”€ perplexity_token: 583.9377\n",
            "â””â”€â”€ TRAINING:\n",
            "    â””â”€â”€ learning_rate: 0.000078\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/3 [00:00<?, ?it/s]/home/agcheria/idl_assignment_Fall_2025/HW4/HW4P1/IDL-HW4/IDL-HW4/hw4lib/trainers/lm_trainer.py:89: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=use_amp):\n",
            "                                                                                                                          \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "ðŸ“Š Metrics (Epoch 38):\n",
            "â”œâ”€â”€ TRAIN:\n",
            "â”‚   â”œâ”€â”€ ce_loss_char: 1.0497\n",
            "â”‚   â”œâ”€â”€ ce_loss_token: 4.3434\n",
            "â”‚   â”œâ”€â”€ perplexity_char: 2.8567\n",
            "â”‚   â””â”€â”€ perplexity_token: 76.9652\n",
            "â””â”€â”€ VAL:\n",
            "    â”œâ”€â”€ ce_loss_char: 1.6121\n",
            "    â”œâ”€â”€ ce_loss_token: 6.3689\n",
            "    â”œâ”€â”€ perplexity_char: 5.0132\n",
            "    â””â”€â”€ perplexity_token: 583.4178\n",
            "â””â”€â”€ TRAINING:\n",
            "    â””â”€â”€ learning_rate: 0.000070\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/3 [00:00<?, ?it/s]/home/agcheria/idl_assignment_Fall_2025/HW4/HW4P1/IDL-HW4/IDL-HW4/hw4lib/trainers/lm_trainer.py:89: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=use_amp):\n",
            "                                                                                                                          \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "ðŸ“Š Metrics (Epoch 39):\n",
            "â”œâ”€â”€ TRAIN:\n",
            "â”‚   â”œâ”€â”€ ce_loss_char: 1.0429\n",
            "â”‚   â”œâ”€â”€ ce_loss_token: 4.3155\n",
            "â”‚   â”œâ”€â”€ perplexity_char: 2.8375\n",
            "â”‚   â””â”€â”€ perplexity_token: 74.8474\n",
            "â””â”€â”€ VAL:\n",
            "    â”œâ”€â”€ ce_loss_char: 1.6141\n",
            "    â”œâ”€â”€ ce_loss_token: 6.3769\n",
            "    â”œâ”€â”€ perplexity_char: 5.0233\n",
            "    â””â”€â”€ perplexity_token: 588.0764\n",
            "â””â”€â”€ TRAINING:\n",
            "    â””â”€â”€ learning_rate: 0.000062\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/3 [00:00<?, ?it/s]/home/agcheria/idl_assignment_Fall_2025/HW4/HW4P1/IDL-HW4/IDL-HW4/hw4lib/trainers/lm_trainer.py:89: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=use_amp):\n",
            "                                                                                                                          \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "ðŸ“Š Metrics (Epoch 40):\n",
            "â”œâ”€â”€ TRAIN:\n",
            "â”‚   â”œâ”€â”€ ce_loss_char: 1.0376\n",
            "â”‚   â”œâ”€â”€ ce_loss_token: 4.2933\n",
            "â”‚   â”œâ”€â”€ perplexity_char: 2.8224\n",
            "â”‚   â””â”€â”€ perplexity_token: 73.2050\n",
            "â””â”€â”€ VAL:\n",
            "    â”œâ”€â”€ ce_loss_char: 1.6122\n",
            "    â”œâ”€â”€ ce_loss_token: 6.3695\n",
            "    â”œâ”€â”€ perplexity_char: 5.0139\n",
            "    â””â”€â”€ perplexity_token: 583.7660\n",
            "â””â”€â”€ TRAINING:\n",
            "    â””â”€â”€ learning_rate: 0.000054\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/3 [00:00<?, ?it/s]/home/agcheria/idl_assignment_Fall_2025/HW4/HW4P1/IDL-HW4/IDL-HW4/hw4lib/trainers/lm_trainer.py:89: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=use_amp):\n",
            "                                                                                                                          \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "ðŸ“Š Metrics (Epoch 41):\n",
            "â”œâ”€â”€ TRAIN:\n",
            "â”‚   â”œâ”€â”€ ce_loss_char: 1.0315\n",
            "â”‚   â”œâ”€â”€ ce_loss_token: 4.2679\n",
            "â”‚   â”œâ”€â”€ perplexity_char: 2.8051\n",
            "â”‚   â””â”€â”€ perplexity_token: 71.3732\n",
            "â””â”€â”€ VAL:\n",
            "    â”œâ”€â”€ ce_loss_char: 1.6099\n",
            "    â”œâ”€â”€ ce_loss_token: 6.3605\n",
            "    â”œâ”€â”€ perplexity_char: 5.0025\n",
            "    â””â”€â”€ perplexity_token: 578.5393\n",
            "â””â”€â”€ TRAINING:\n",
            "    â””â”€â”€ learning_rate: 0.000047\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/3 [00:00<?, ?it/s]/home/agcheria/idl_assignment_Fall_2025/HW4/HW4P1/IDL-HW4/IDL-HW4/hw4lib/trainers/lm_trainer.py:89: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=use_amp):\n",
            "                                                                                                                          \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "ðŸ“Š Metrics (Epoch 42):\n",
            "â”œâ”€â”€ TRAIN:\n",
            "â”‚   â”œâ”€â”€ ce_loss_char: 1.0259\n",
            "â”‚   â”œâ”€â”€ ce_loss_token: 4.2450\n",
            "â”‚   â”œâ”€â”€ perplexity_char: 2.7896\n",
            "â”‚   â””â”€â”€ perplexity_token: 69.7553\n",
            "â””â”€â”€ VAL:\n",
            "    â”œâ”€â”€ ce_loss_char: 1.6098\n",
            "    â”œâ”€â”€ ce_loss_token: 6.3598\n",
            "    â”œâ”€â”€ perplexity_char: 5.0016\n",
            "    â””â”€â”€ perplexity_token: 578.1193\n",
            "â””â”€â”€ TRAINING:\n",
            "    â””â”€â”€ learning_rate: 0.000041\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/3 [00:00<?, ?it/s]/home/agcheria/idl_assignment_Fall_2025/HW4/HW4P1/IDL-HW4/IDL-HW4/hw4lib/trainers/lm_trainer.py:89: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=use_amp):\n",
            "                                                                                                                          \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "ðŸ“Š Metrics (Epoch 43):\n",
            "â”œâ”€â”€ TRAIN:\n",
            "â”‚   â”œâ”€â”€ ce_loss_char: 1.0230\n",
            "â”‚   â”œâ”€â”€ ce_loss_token: 4.2331\n",
            "â”‚   â”œâ”€â”€ perplexity_char: 2.7816\n",
            "â”‚   â””â”€â”€ perplexity_token: 68.9276\n",
            "â””â”€â”€ VAL:\n",
            "    â”œâ”€â”€ ce_loss_char: 1.6104\n",
            "    â”œâ”€â”€ ce_loss_token: 6.3625\n",
            "    â”œâ”€â”€ perplexity_char: 5.0050\n",
            "    â””â”€â”€ perplexity_token: 579.6798\n",
            "â””â”€â”€ TRAINING:\n",
            "    â””â”€â”€ learning_rate: 0.000034\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/3 [00:00<?, ?it/s]/home/agcheria/idl_assignment_Fall_2025/HW4/HW4P1/IDL-HW4/IDL-HW4/hw4lib/trainers/lm_trainer.py:89: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=use_amp):\n",
            "                                                                                                                          \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "ðŸ“Š Metrics (Epoch 44):\n",
            "â”œâ”€â”€ TRAIN:\n",
            "â”‚   â”œâ”€â”€ ce_loss_char: 1.0209\n",
            "â”‚   â”œâ”€â”€ ce_loss_token: 4.2241\n",
            "â”‚   â”œâ”€â”€ perplexity_char: 2.7756\n",
            "â”‚   â””â”€â”€ perplexity_token: 68.3129\n",
            "â””â”€â”€ VAL:\n",
            "    â”œâ”€â”€ ce_loss_char: 1.6105\n",
            "    â”œâ”€â”€ ce_loss_token: 6.3626\n",
            "    â”œâ”€â”€ perplexity_char: 5.0052\n",
            "    â””â”€â”€ perplexity_token: 579.7652\n",
            "â””â”€â”€ TRAINING:\n",
            "    â””â”€â”€ learning_rate: 0.000029\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/3 [00:00<?, ?it/s]/home/agcheria/idl_assignment_Fall_2025/HW4/HW4P1/IDL-HW4/IDL-HW4/hw4lib/trainers/lm_trainer.py:89: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=use_amp):\n",
            "                                                                                                                          \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "ðŸ“Š Metrics (Epoch 45):\n",
            "â”œâ”€â”€ TRAIN:\n",
            "â”‚   â”œâ”€â”€ ce_loss_char: 1.0167\n",
            "â”‚   â”œâ”€â”€ ce_loss_token: 4.2070\n",
            "â”‚   â”œâ”€â”€ perplexity_char: 2.7641\n",
            "â”‚   â””â”€â”€ perplexity_token: 67.1542\n",
            "â””â”€â”€ VAL:\n",
            "    â”œâ”€â”€ ce_loss_char: 1.6105\n",
            "    â”œâ”€â”€ ce_loss_token: 6.3627\n",
            "    â”œâ”€â”€ perplexity_char: 5.0053\n",
            "    â””â”€â”€ perplexity_token: 579.8039\n",
            "â””â”€â”€ TRAINING:\n",
            "    â””â”€â”€ learning_rate: 0.000023\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/3 [00:00<?, ?it/s]/home/agcheria/idl_assignment_Fall_2025/HW4/HW4P1/IDL-HW4/IDL-HW4/hw4lib/trainers/lm_trainer.py:89: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=use_amp):\n",
            "                                                                                                                          \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "ðŸ“Š Metrics (Epoch 46):\n",
            "â”œâ”€â”€ TRAIN:\n",
            "â”‚   â”œâ”€â”€ ce_loss_char: 1.0139\n",
            "â”‚   â”œâ”€â”€ ce_loss_token: 4.1954\n",
            "â”‚   â”œâ”€â”€ perplexity_char: 2.7564\n",
            "â”‚   â””â”€â”€ perplexity_token: 66.3827\n",
            "â””â”€â”€ VAL:\n",
            "    â”œâ”€â”€ ce_loss_char: 1.6110\n",
            "    â”œâ”€â”€ ce_loss_token: 6.3647\n",
            "    â”œâ”€â”€ perplexity_char: 5.0078\n",
            "    â””â”€â”€ perplexity_token: 580.9613\n",
            "â””â”€â”€ TRAINING:\n",
            "    â””â”€â”€ learning_rate: 0.000019\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/3 [00:00<?, ?it/s]/home/agcheria/idl_assignment_Fall_2025/HW4/HW4P1/IDL-HW4/IDL-HW4/hw4lib/trainers/lm_trainer.py:89: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=use_amp):\n",
            "                                                                                                                          \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "ðŸ“Š Metrics (Epoch 47):\n",
            "â”œâ”€â”€ TRAIN:\n",
            "â”‚   â”œâ”€â”€ ce_loss_char: 1.0121\n",
            "â”‚   â”œâ”€â”€ ce_loss_token: 4.1878\n",
            "â”‚   â”œâ”€â”€ perplexity_char: 2.7513\n",
            "â”‚   â””â”€â”€ perplexity_token: 65.8769\n",
            "â””â”€â”€ VAL:\n",
            "    â”œâ”€â”€ ce_loss_char: 1.6114\n",
            "    â”œâ”€â”€ ce_loss_token: 6.3664\n",
            "    â”œâ”€â”€ perplexity_char: 5.0100\n",
            "    â””â”€â”€ perplexity_token: 581.9431\n",
            "â””â”€â”€ TRAINING:\n",
            "    â””â”€â”€ learning_rate: 0.000014\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/3 [00:00<?, ?it/s]/home/agcheria/idl_assignment_Fall_2025/HW4/HW4P1/IDL-HW4/IDL-HW4/hw4lib/trainers/lm_trainer.py:89: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=use_amp):\n",
            "                                                                                                                          \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "ðŸ“Š Metrics (Epoch 48):\n",
            "â”œâ”€â”€ TRAIN:\n",
            "â”‚   â”œâ”€â”€ ce_loss_char: 1.0110\n",
            "â”‚   â”œâ”€â”€ ce_loss_token: 4.1832\n",
            "â”‚   â”œâ”€â”€ perplexity_char: 2.7483\n",
            "â”‚   â””â”€â”€ perplexity_token: 65.5730\n",
            "â””â”€â”€ VAL:\n",
            "    â”œâ”€â”€ ce_loss_char: 1.6111\n",
            "    â”œâ”€â”€ ce_loss_token: 6.3651\n",
            "    â”œâ”€â”€ perplexity_char: 5.0083\n",
            "    â””â”€â”€ perplexity_token: 581.1929\n",
            "â””â”€â”€ TRAINING:\n",
            "    â””â”€â”€ learning_rate: 0.000011\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Training LM]:   0%|          | 0/3 [00:00<?, ?it/s]/home/agcheria/idl_assignment_Fall_2025/HW4/HW4P1/IDL-HW4/IDL-HW4/hw4lib/trainers/lm_trainer.py:89: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=use_amp):\n",
            "                                                                                                                          \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating with greedy search...\n",
            "\n",
            "ðŸ“Š Metrics (Epoch 49):\n",
            "â”œâ”€â”€ TRAIN:\n",
            "â”‚   â”œâ”€â”€ ce_loss_char: 1.0090\n",
            "â”‚   â”œâ”€â”€ ce_loss_token: 4.1751\n",
            "â”‚   â”œâ”€â”€ perplexity_char: 2.7429\n",
            "â”‚   â””â”€â”€ perplexity_token: 65.0448\n",
            "â””â”€â”€ VAL:\n",
            "    â”œâ”€â”€ ce_loss_char: 1.6103\n",
            "    â”œâ”€â”€ ce_loss_token: 6.3619\n",
            "    â”œâ”€â”€ perplexity_char: 5.0043\n",
            "    â””â”€â”€ perplexity_token: 579.3645\n",
            "â””â”€â”€ TRAINING:\n",
            "    â””â”€â”€ learning_rate: 0.000007\n"
          ]
        }
      ],
      "source": [
        "trainer.train(train_loader, val_loader, epochs=config['training']['epochs'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j55r9gK_7Q68"
      },
      "source": [
        "# Evaluate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "72D0yzHr7Q68"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ðŸ“Š Metrics (Epoch 50):\n",
            "â””â”€â”€ TEST:\n",
            "    â”œâ”€â”€ ce_loss_char: 1.7637\n",
            "    â”œâ”€â”€ ce_loss_token: 6.5683\n",
            "    â”œâ”€â”€ perplexity_char: 5.8343\n",
            "    â””â”€â”€ perplexity_token: 712.1301\n",
            "â””â”€â”€ TRAINING:\n",
            "    â””â”€â”€ learning_rate: 0.000007\n",
            "Generating with greedy search...\n",
            "Generating with greedy search...\n",
            "Generating with greedy search...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "uploading checkpoints/checkpoint-best-metric-model.pth 134.8MB/203.2MB (3.2s)<br>uploading checkpoints/checkpoint-last-epoch-model.pth 138.1MB/203.2MB (3.2s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Control-C detected -- Run data was not synced\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m test_metrics, test_generation_results = trainer.evaluate(test_loader)\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Cleanup\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcleanup\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/idl_assignment_Fall_2025/HW4/HW4P1/IDL-HW4/IDL-HW4/hw4lib/trainers/base_trainer.py:376\u001b[39m, in \u001b[36mBaseTrainer.cleanup\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    374\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Cleanup resources.\"\"\"\u001b[39;00m\n\u001b[32m    375\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.use_wandb \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.wandb_run:\n\u001b[32m--> \u001b[39m\u001b[32m376\u001b[39m     \u001b[43mwandb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfinish\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/hw4/lib/python3.12/site-packages/wandb/sdk/wandb_run.py:4158\u001b[39m, in \u001b[36mfinish\u001b[39m\u001b[34m(exit_code, quiet)\u001b[39m\n\u001b[32m   4141\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Finish a run and upload any remaining data.\u001b[39;00m\n\u001b[32m   4142\u001b[39m \n\u001b[32m   4143\u001b[39m \u001b[33;03mMarks the completion of a W&B run and ensures all data is synced to the server.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   4155\u001b[39m \u001b[33;03m    quiet: Deprecated. Configure logging verbosity using `wandb.Settings(quiet=...)`.\u001b[39;00m\n\u001b[32m   4156\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4157\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m wandb.run:\n\u001b[32m-> \u001b[39m\u001b[32m4158\u001b[39m     \u001b[43mwandb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfinish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexit_code\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexit_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquiet\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquiet\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/hw4/lib/python3.12/site-packages/wandb/sdk/wandb_run.py:442\u001b[39m, in \u001b[36m_run_decorator._noop.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    439\u001b[39m         wandb.termwarn(message, repeat=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    440\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.Dummy()\n\u001b[32m--> \u001b[39m\u001b[32m442\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/hw4/lib/python3.12/site-packages/wandb/sdk/wandb_run.py:384\u001b[39m, in \u001b[36m_run_decorator._attach.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    382\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    383\u001b[39m     \u001b[38;5;28mcls\u001b[39m._is_attaching = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m384\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/hw4/lib/python3.12/site-packages/wandb/sdk/wandb_run.py:2134\u001b[39m, in \u001b[36mRun.finish\u001b[39m\u001b[34m(self, exit_code, quiet)\u001b[39m\n\u001b[32m   2126\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m quiet \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2127\u001b[39m     deprecate.deprecate(\n\u001b[32m   2128\u001b[39m         field_name=deprecate.Deprecated.run__finish_quiet,\n\u001b[32m   2129\u001b[39m         warning_message=(\n\u001b[32m   (...)\u001b[39m\u001b[32m   2132\u001b[39m         ),\n\u001b[32m   2133\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m2134\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_finish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexit_code\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/hw4/lib/python3.12/site-packages/wandb/sdk/wandb_run.py:2164\u001b[39m, in \u001b[36mRun._finish\u001b[39m\u001b[34m(self, exit_code)\u001b[39m\n\u001b[32m   2161\u001b[39m \u001b[38;5;28mself\u001b[39m._is_finished = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   2163\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2164\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_atexit_cleanup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexit_code\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexit_code\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2166\u001b[39m     \u001b[38;5;66;03m# Run hooks that should happen after the last messages to the\u001b[39;00m\n\u001b[32m   2167\u001b[39m     \u001b[38;5;66;03m# internal service, like detaching the logger.\u001b[39;00m\n\u001b[32m   2168\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._teardown_hooks:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/hw4/lib/python3.12/site-packages/wandb/sdk/wandb_run.py:2392\u001b[39m, in \u001b[36mRun._atexit_cleanup\u001b[39m\u001b[34m(self, exit_code)\u001b[39m\n\u001b[32m   2389\u001b[39m         os.remove(\u001b[38;5;28mself\u001b[39m._settings.resume_fname)\n\u001b[32m   2391\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2392\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_on_finish\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2394\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[32m   2395\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m wandb.wandb_agent._is_running():  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/hw4/lib/python3.12/site-packages/wandb/sdk/wandb_run.py:2644\u001b[39m, in \u001b[36mRun._on_finish\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2637\u001b[39m exit_handle.add_probe(on_probe=\u001b[38;5;28mself\u001b[39m._on_probe_exit)\n\u001b[32m   2639\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m progress.progress_printer(\n\u001b[32m   2640\u001b[39m     \u001b[38;5;28mself\u001b[39m._printer,\n\u001b[32m   2641\u001b[39m     \u001b[38;5;28mself\u001b[39m._settings,\n\u001b[32m   2642\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m progress_printer:\n\u001b[32m   2643\u001b[39m     \u001b[38;5;66;03m# Wait for the run to complete.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2644\u001b[39m     _ = \u001b[43mexit_handle\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2645\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2646\u001b[39m \u001b[43m        \u001b[49m\u001b[43mon_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunctools\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2647\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_on_progress_exit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2648\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_printer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2649\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2650\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2652\u001b[39m \u001b[38;5;66;03m# Print some final statistics.\u001b[39;00m\n\u001b[32m   2653\u001b[39m poll_exit_handle = \u001b[38;5;28mself\u001b[39m._backend.interface.deliver_poll_exit()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/hw4/lib/python3.12/site-packages/wandb/sdk/lib/mailbox.py:279\u001b[39m, in \u001b[36mMailboxHandle.wait\u001b[39m\u001b[34m(self, timeout, on_probe, on_progress, release, cancel)\u001b[39m\n\u001b[32m    276\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._interface._transport_keepalive_failed():\n\u001b[32m    277\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m MailboxError(\u001b[33m\"\u001b[39m\u001b[33mtransport failed\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m279\u001b[39m found, abandoned = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_slot\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_and_clear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwait_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    280\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m found:\n\u001b[32m    281\u001b[39m     \u001b[38;5;66;03m# Always update progress to 100% when done\u001b[39;00m\n\u001b[32m    282\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m on_progress \u001b[38;5;129;01mand\u001b[39;00m progress_handle \u001b[38;5;129;01mand\u001b[39;00m progress_sent:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/hw4/lib/python3.12/site-packages/wandb/sdk/lib/mailbox.py:126\u001b[39m, in \u001b[36m_MailboxSlot._get_and_clear\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_and_clear\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout: \u001b[38;5;28mfloat\u001b[39m) -> Tuple[Optional[pb.Result], \u001b[38;5;28mbool\u001b[39m]:\n\u001b[32m    125\u001b[39m     found = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    127\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n\u001b[32m    128\u001b[39m             found = \u001b[38;5;28mself\u001b[39m._result\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/hw4/lib/python3.12/site-packages/wandb/sdk/lib/mailbox.py:122\u001b[39m, in \u001b[36m_MailboxSlot._wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_wait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout: \u001b[38;5;28mfloat\u001b[39m) -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_event\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/hw4/lib/python3.12/threading.py:655\u001b[39m, in \u001b[36mEvent.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    653\u001b[39m signaled = \u001b[38;5;28mself\u001b[39m._flag\n\u001b[32m    654\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[32m--> \u001b[39m\u001b[32m655\u001b[39m     signaled = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cond\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/hw4/lib/python3.12/threading.py:359\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    357\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    358\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m         gotit = \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    360\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    361\u001b[39m         gotit = waiter.acquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "test_metrics, test_generation_results = trainer.evaluate(test_loader)\n",
        "# Cleanup\n",
        "trainer.cleanup()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHw8LJp07Q68"
      },
      "source": [
        "# Submission\n",
        "To submit your assignment, you will need to create a `handin.tar` with the following directory structure:\n",
        "\n",
        "```\n",
        "handin/\n",
        "â”œâ”€â”€ mytorch/                     # Your implemented modules\n",
        "â”œâ”€â”€ test_metrics.json            # Results from evaluation\n",
        "â”œâ”€â”€ test_generated_results.json  # Sample text generations\n",
        "â””â”€â”€ model_arch.txt               # Model architecture summary\n",
        "```\n",
        "\n",
        "- Simply run the cell below once you are satisfied with your current state and this will create the `handin.tar` file.\n",
        "- After running the above cell, you should see the handin.tar file in the current directory\n",
        "- Upload the `handin.tar` file to the `HW4P1` assignment on Autolab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVSPaoOF7Q68"
      },
      "outputs": [],
      "source": [
        "# Create temporary handin directory\n",
        "if os.path.exists('handin'):\n",
        "    shutil.rmtree('handin')\n",
        "os.makedirs('handin')\n",
        "\n",
        "# Copy mytorch directory\n",
        "shutil.copytree('mytorch', 'handin/mytorch')\n",
        "\n",
        "# Save final results\n",
        "with open('handin/test_metrics.json', 'w') as f:\n",
        "    json.dump(test_metrics, f, indent=4)\n",
        "\n",
        "with open('handin/test_generated_results.json', 'w') as f:\n",
        "    json.dump(test_generation_results['greedy'], f, indent=4)\n",
        "\n",
        "# Save model architecture\n",
        "with open('handin/model_arch.txt', 'w') as f:\n",
        "    f.write(str(model_stats))\n",
        "\n",
        "# Create tar file with all exclusions handled by filter\n",
        "with tarfile.open('handin.tar', 'w') as tar:\n",
        "    def filter_files(tarinfo):\n",
        "        # Skip unwanted files\n",
        "        if any(pattern in tarinfo.name for pattern in [\n",
        "            '.DS_Store',\n",
        "            '__pycache__',\n",
        "            '.pyc'\n",
        "        ]):\n",
        "            return None\n",
        "        return tarinfo\n",
        "\n",
        "    tar.add('handin', arcname='handin', filter=filter_files)\n",
        "\n",
        "# Cleanup\n",
        "shutil.rmtree('handin')\n",
        "\n",
        "print(\"Created handin.tar successfully!\")\n",
        "\n",
        "## After running the above cell, you should see the handin.tar file in the current directory\n",
        "!ls"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "qQG51p6e7Q6x"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "hw4",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
