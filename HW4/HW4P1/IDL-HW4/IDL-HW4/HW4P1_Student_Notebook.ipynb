{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3ytyXW-7Q6o"
      },
      "source": [
        "# Setup\n",
        "-  Follow the setup instructions based on your preferred environment!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeJDFDo87Q6s"
      },
      "source": [
        "## Local"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xg5oyR8XzQRY"
      },
      "source": [
        "One of our key goals in designing this assignment is to allow you to complete most of the preliminary implementation work locally.  \n",
        "We highly recommend that you **pass all tests locally** using the provided `hw4_data_subset` before moving to a GPU runtime.  \n",
        "To do this, simply:\n",
        "\n",
        "### Create a new conda environment\n",
        "```bash\n",
        "# Be sure to deactivate any active environments first\n",
        "conda create -n hw4 python=3.12.4\n",
        "```\n",
        "\n",
        "### Activate the conda environment\n",
        "```bash\n",
        "conda activate hw4\n",
        "```\n",
        "\n",
        "### Install the dependencies using the provided `requirements.txt`\n",
        "```bash\n",
        "pip install --no-cache-dir --ignore-installed -r requirements.txt\n",
        "```\n",
        "\n",
        "### Ensure that your notebook is in the same working directory as the `Handout`\n",
        "This can be achieved by:\n",
        "1. Physically moving the notebook into the handout directory.\n",
        "2. Changing the notebook‚Äôs current working directory to the handout directory using the os.chdir() function.\n",
        "\n",
        "### Open the notebook and select the newly created environment from the kernel selector.\n",
        "\n",
        "If everything was done correctly, You should see atleast the following files in your current working directory after running `!ls`:\n",
        "```\n",
        ".\n",
        "‚îú‚îÄ‚îÄ README.md\n",
        "‚îú‚îÄ‚îÄ requirements.txt\n",
        "‚îú‚îÄ‚îÄ hw4lib/\n",
        "‚îú‚îÄ‚îÄ mytorch/\n",
        "‚îú‚îÄ‚îÄ tests/\n",
        "‚îî‚îÄ‚îÄ hw4_data_subset/\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tub92oPW7Q6t"
      },
      "source": [
        "## Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5qfxCxq7l-f"
      },
      "source": [
        "### Step 1: Get your handout\n",
        "- See writeup for recommended approaches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V0wRO-k-7Q6u"
      },
      "outputs": [],
      "source": [
        "# Example: My preferred approach\n",
        "import os\n",
        "# Settings -> Developer Settings -> Personal Access Tokens -> Token (classic)\n",
        "os.environ['GITHUB_TOKEN'] = \"your_token_here\"\n",
        "\n",
        "GITHUB_USERNAME = \"your_username_here\"\n",
        "REPO_NAME       = \"your_repo_name_here\"\n",
        "TOKEN = os.environ.get(\"GITHUB_TOKEN\")\n",
        "repo_url        = f\"https://{TOKEN}@github.com/{GITHUB_USERNAME}/{REPO_NAME}.git\"\n",
        "!git clone {repo_url}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KmxMiKjIYv2_"
      },
      "outputs": [],
      "source": [
        "# To pull latest changes (Must be in the repo dir, use pwd/ls to verify)\n",
        "!cd {REPO_NAME} && git pull"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfOQStjw7Q6w"
      },
      "source": [
        "### Step 2: Install Dependencies\n",
        "- `NOTE`: Your runtime will be restarted to ensure all dependencies are updated.\n",
        "- `NOTE`: You will see a runtime crashed message, this was intentionally done. Simply move on to the next cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "maupv9q17Q6w"
      },
      "outputs": [],
      "source": [
        "%pip install --no-deps -r IDL-HW4/requirements.txt\n",
        "import os\n",
        "os.kill(os.getpid(), 9) # NOTE: This will restart the your colab Python runtime (required)!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Yj32DflNHuI"
      },
      "source": [
        "### Step 3: Obtain Data\n",
        "\n",
        "- `NOTE`: This process will automatically download and unzip data for both `HW4P1` and `HW4P2`.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KeP-XgwYA_M3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0Warning: Failed to open the file /content/f25-hw4-data.zip: No such file or \n",
            "Warning: directory\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "curl: (23) Failure writing output to destination\n",
            "unzip:  cannot find or open /content/f25-hw4-data.zip, /content/f25-hw4-data.zip.zip or /content/f25-hw4-data.zip.ZIP.\n",
            "du: cannot access '/content/hw4_data': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!curl -L -o /content/f25-hw4-data.zip https://www.kaggle.com/datasets/cmu11785/f25-11785-hw4-data\n",
        "!unzip -q -o /content/f25-hw4-data.zip -d /content/hw4_data\n",
        "!rm -rf /content/f25-hw4-data.zip\n",
        "!du -h --max-depth=2 /content/hw4_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2YwJ0hy7Q6x"
      },
      "source": [
        "### Step 4: Move to Handout Directory\n",
        "You must be within the handout directory for the library imports to work!\n",
        "\n",
        "- `NOTE`: You may have to repeat running this command anytime you restart your runtime.\n",
        "- `NOTE`: You can do a `pwd` to check if you are in the right directory.\n",
        "- `NOTE`: The way it is setup currently, Your data directory should be one level up from your project directory. Keep this in mind when you are setting your `root` in the config file.\n",
        "\n",
        "If everything was done correctly, You should see atleast the following files in your current working directory after running `!ls`:\n",
        "```\n",
        ".\n",
        "‚îú‚îÄ‚îÄ README.md\n",
        "‚îú‚îÄ‚îÄ requirements.txt\n",
        "‚îú‚îÄ‚îÄ hw4lib/\n",
        "‚îú‚îÄ‚îÄ mytorch/\n",
        "‚îú‚îÄ‚îÄ tests/\n",
        "‚îî‚îÄ‚îÄ hw4_data_subset/\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fzYdDIxw7Q6x"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('IDL-HW4')\n",
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EPDWOj2zQRb"
      },
      "source": [
        "## Kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iG1hgl5OzQRb"
      },
      "source": [
        "While it is possible to run the notebook on Kaggle, we would recommend against it. This assignment is more resource intensive and may run slower on Kaggle."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rE98B67SzQRb"
      },
      "source": [
        "### Step 1: Get your handout\n",
        "- See writeup for recommended approaches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZxCPYQnzQRb"
      },
      "outputs": [],
      "source": [
        "# Example: My preferred approach\n",
        "import os\n",
        "# Settings -> Developer Settings -> Personal Access Tokens -> Token (classic)\n",
        "os.environ['GITHUB_TOKEN'] = \"your_token_here\"\n",
        "\n",
        "GITHUB_USERNAME = \"your_username_here\"\n",
        "REPO_NAME       = \"your_repo_name_here\"\n",
        "TOKEN = os.environ.get(\"GITHUB_TOKEN\")\n",
        "repo_url        = f\"https://{TOKEN}@github.com/{GITHUB_USERNAME}/{REPO_NAME}.git\"\n",
        "!git clone {repo_url}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZEcrVK2azQRb"
      },
      "outputs": [],
      "source": [
        "# To pull latest changes (Must be in the repo dir, use pwd/ls to verify)\n",
        "!cd {REPO_NAME} && git pull"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOWDhaYfzQRb"
      },
      "source": [
        "### Step 2: Install Dependencies\n",
        "- Simply set the `Environment` setting in the notebook to `Always use latest environment`. No need to install anything."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jc_kHNdXzQRb"
      },
      "source": [
        "### Step 3: Obtain Data\n",
        "\n",
        "#### ‚ö†Ô∏è Important: Kaggle Users  \n",
        "If you are using Kaggle, **do not manually download the data!** The dataset is large and may exceed your available disk space. Instead, follow these steps to add the dataset directly to your notebook:\n",
        "\n",
        "1. Open your **Kaggle Notebook**.  \n",
        "2. Navigate to **Notebook ‚Üí Input**.  \n",
        "3. Click **Add Input**.  \n",
        "4. In the search bar, paste the following URL:  \n",
        "   üëâ [https://www.kaggle.com/datasets/cmu11785/f25-11785-hw4-data](https://www.kaggle.com/datasets/cmu11785/f25-11785-hw4-data)  \n",
        "5. Click the **‚ûï (plus sign)** to add the dataset to your notebook.  \n",
        "\n",
        "#### üìå Note:  \n",
        "This process will automatically download and unzip data for both `HW4P1` and `HW4P2`.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUyrqn8DzQRb"
      },
      "source": [
        "### Step 4: Move to Handout Directory\n",
        "You must be within the handout directory for the library imports to work!\n",
        "\n",
        "- `NOTE`: You may have to repeat running this command anytime you restart your runtime.\n",
        "- `NOTE`: You can do a `pwd` to check if you are in the right directory.\n",
        "- `NOTE`: The way it is setup currently, Your data directory should be one level up from your project directory. Keep this in mind when you are setting your `root` in the config file.\n",
        "\n",
        "If everything was done correctly, You should see atleast the following files in your current working directory after running `!ls`:\n",
        "```\n",
        ".\n",
        "‚îú‚îÄ‚îÄ README.md\n",
        "‚îú‚îÄ‚îÄ requirements.txt\n",
        "‚îú‚îÄ‚îÄ hw4lib/\n",
        "‚îú‚îÄ‚îÄ mytorch/\n",
        "‚îú‚îÄ‚îÄ tests/\n",
        "‚îî‚îÄ‚îÄ hw4_data_subset/\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E9M6SncbzQRb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('IDL-HW4')\n",
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uP0Aucc7XWXs"
      },
      "source": [
        "## PSC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJm_aSHvXWXs"
      },
      "source": [
        "### 1Ô∏è‚É£ **Step 1 Setting Up Your Environment on Bridges2**\n",
        "\n",
        "‚ùóÔ∏è‚ö†Ô∏è For this homework, we are **providing shared Datasets and a shared Conda environment** for the entire class.\n",
        "\n",
        "‚ùóÔ∏è‚ö†Ô∏è So for PSC users, **do not download the data yourself** and **do not need to manually install the packages**!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Lf3a_SI7E8l"
      },
      "source": [
        "Follow these steps to set up the environment and start a Jupyter notebook on Bridges2:\n",
        "\n",
        "To run your notebook more efficiently on PSC, we need to use a **Jupyter Server** hosted on a compute node.\n",
        "\n",
        "You can use your prefered way of connecting to the Jupyter Server. Your options should be covered in the docs linked in post 558 @ piazza."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyCQpcT07HQm"
      },
      "source": [
        "**The recommended way of connecting is:**\n",
        "\n",
        "#### **Connect in VSCode**\n",
        "SSH into Bridges2 and navigate to your **Jet directory** (`Jet/home/<your_psc_username>`). Upload your notebook there, and then connect to the Jupyter Server from that directory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgivK7YU7J2g"
      },
      "source": [
        "#### **1. SSH into Bridges2**\n",
        "1ÔºâOpen VS Code and click on the `Extensions` icon in the left sidebar. Make sure the \"**Remote - SSH**\" extension is installed.\n",
        "\n",
        "2ÔºâOpen the command palette (**Shift+Command+P** on Mac, **Ctrl+Shift+P** on Windows). A search box will appear at the top center. Choose `\"Remote-SSH: Add New SSH Host\"`, then enter:\n",
        "\n",
        "```bash\n",
        "ssh <your_username>@bridges2.psc.edu #change <your_username> to your username\n",
        "```\n",
        "\n",
        "Next, choose `\"/Users/<your_username>/.ssh/config\"` as the config file. A dialog will appear in the bottom right saying \"Host Added\". Click `\"Connect\"`, and then enter your password.\n",
        "\n",
        "(Note: After adding the host once, you can later use `\"Remote-SSH: Connect to Host\"` and select \"bridges2.psc.edu\" from the list.)\n",
        "\n",
        "3ÔºâOnce connected, click `\"Explorer\"` in the left sidebar > \"Open Folder\", and navigate to your home directory under the project grant:\n",
        "```bash\n",
        "/jet/home/<your_username>  #change <your_username> to your username\n",
        "```\n",
        "\n",
        "4ÔºâYou can now drag your notebook files directly into the right-hand pane (your remote home directory), or upload them using `scp` into your folder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EooKLI57OWj"
      },
      "source": [
        "> ‚ùóÔ∏è‚ö†Ô∏è The following steps should be executed in the **VSCode integrated terminal**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euHM_evw7Qgz"
      },
      "source": [
        "#### **2. Navigate to Your Directory**\n",
        "Make sure to use this `/jet/home/<your_username>` as your working directory, since all subsequent operations (up to submission) are based on this path.\n",
        "```bash\n",
        "cd /jet/home/<your_username>  #change <your_username> to your username\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cAM9ezJ7S7o"
      },
      "source": [
        "#### **3. Request a Compute Node**\n",
        "```bash\n",
        "interact -p GPU-shared --gres=gpu:v100-32:1 -t 8:00:00 -A cis250019p\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-LgJDnc7UwG"
      },
      "source": [
        "#### **4. Load the Anaconda Module**\n",
        "```bash\n",
        "module load anaconda3\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XhBfy767WjV"
      },
      "source": [
        "#### **5. Activate the provided HW4 Environment**\n",
        "```bash\n",
        "conda deactivate # First, deactivate any existing Conda environment\n",
        "conda activate /ocean/projects/cis250019p/mzhang23/TA/HW4/envs/hw4_env && export PYTHONNOUSERSITE=1\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mwhhtkm97dNC"
      },
      "source": [
        "#### **6. Start Jupyter Notebook**\n",
        "Launch Jupyter Notebook:\n",
        "```bash\n",
        "jupyter notebook --no-browser --ip=0.0.0.0\n",
        "```\n",
        "\n",
        "Go to **Kernel** ‚Üí **Select Another Kernel** ‚Üí **Existing Jupyter Server**\n",
        "   Enter the URL of the Jupyter Server:```http://{hostname}:{port}/tree?token={token}```\n",
        "   \n",
        "   *(Usually, this URL appears in the terminal output after you run `jupyter notebook --no-browser --ip=0.0.0.0`, in a line like:  ‚ÄúJupyter Server is running at: http://...‚Äù)*\n",
        "\n",
        "   - eg: `http://v011.ib.bridges2.psc.edu:8888/tree?token=e4b302434e68990f28bc2b4ae8d216eb87eecb7090526249`\n",
        "\n",
        "> **Note**: Replace `{hostname}`, `{port}` and `{token}` with your actual values from the Jupyter output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHvhs7qP7ghQ"
      },
      "source": [
        "After launching the Jupyter notebook, you can run the cells directly inside the notebook ‚Äî no need to use the terminal for the remaining steps."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCemuI9_70PG"
      },
      "source": [
        "### 2Ô∏è‚É£ Step 2: Get Repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eaClGC468DoA"
      },
      "outputs": [],
      "source": [
        "#Make sure you are in your directory\n",
        "!pwd #should be /jet/home/<your_username>, if not, uncomment the following line and replace with your actual username:\n",
        "# %cd /jet/home/<your_username>\n",
        "#TODO: replace the \"<your_username>\" to yours"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "simQXvJoXWXs"
      },
      "outputs": [],
      "source": [
        "# Example: My preferred approach\n",
        "import os\n",
        "# Settings -> Developer Settings -> Personal Access Tokens -> Token (classic)\n",
        "os.environ['GITHUB_TOKEN'] = \"your_github_token_here\"\n",
        "\n",
        "GITHUB_USERNAME = \"your_github_username_here\"\n",
        "REPO_NAME       = \"your_github_repo_name_here\"\n",
        "TOKEN = os.environ.get(\"GITHUB_TOKEN\")\n",
        "repo_url        = f\"https://{TOKEN}@github.com/{GITHUB_USERNAME}/{REPO_NAME}.git\"\n",
        "!git clone {repo_url}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Ibi0yUFXWXs"
      },
      "outputs": [],
      "source": [
        "# To pull latest changes (Must be in the repo dir, use pwd/ls to verify)\n",
        "!cd {REPO_NAME} && git pull"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPU5y0G68brJ"
      },
      "source": [
        "#### **Move to Project Directory**\n",
        "- `NOTE`: You may have to repeat this on anytime you restart your runtime. You can do a `pwd` or `ls` to check if you are in the right directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jtwYL_8q8Z5N"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('IDL-HW4')\n",
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVHYLiYb8exP"
      },
      "source": [
        "### 3Ô∏è‚É£ **Step 3: Set up Kaggle API Authentication**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y6QWOFH98h07"
      },
      "outputs": [],
      "source": [
        "# TODO: Use the same Kaggle code from HW3P2\n",
        "!mkdir /jet/home/<your_username>/.kaggle #TODO: replace the \"<your_username>\" to yours\n",
        "\n",
        "with open(\"/jet/home/<your_username>/.kaggle/kaggle.json\", \"w+\") as f: #TODO: replace the \"<your_username>\" to yours\n",
        "    f.write('{\"username\":\"<your_username>\",\"key\":\"<your_key>\"}')\n",
        "    # TODO: Put your kaggle username & key here\n",
        "\n",
        "!chmod 600 /jet/home/<your_username>/.kaggle/kaggle.json #TODO: replace the \"<your_username>\" to yours"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHsBwCDn8kkq"
      },
      "source": [
        "### 4Ô∏è‚É£ **Step 4: Get Data**\n",
        "\n",
        "‚ùóÔ∏è‚ö†Ô∏è The data used in this assignment is **already stored in a shared, read-only folder, so you do not need to manually download anything**.\n",
        "\n",
        "Instead, just make sure to replace the dataset path in your notebook code with the correct path from the shared directory.\n",
        "\n",
        "You can run the following block to explore the shared directory structure:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RFpjyS0z8nO_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "data_path = \"/ocean/projects/cis250019p/mzhang23/TA/HW4/hw4p1_data\" #Shared data path, do not need to change the username to yours\n",
        "print(\"Files in shared hw4p2 dataset:\", os.listdir(data_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xc9dAkrP8rof"
      },
      "outputs": [],
      "source": [
        "!apt-get install tree\n",
        "!tree -L 2 /ocean/projects/cis250019p/mzhang23/TA/HW4/hw4p1_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhPm0t5d7Q6z"
      },
      "source": [
        "# Imports\n",
        "\n",
        "- If your setup was done correctly, you should be able to run the following cell without any issues."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YAJF1-E87Q6z"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "from hw4lib.data import (\n",
        "    H4Tokenizer,\n",
        "    LMDataset,\n",
        "    verify_dataloader\n",
        ")\n",
        "from hw4lib.model import (\n",
        "    CausalMask,\n",
        "    PadMask,\n",
        "    PositionalEncoding,\n",
        "    DecoderOnlyTransformer\n",
        ")\n",
        "from hw4lib.utils import (\n",
        "    create_optimizer,\n",
        "    create_scheduler,\n",
        "    plot_lr_schedule\n",
        ")\n",
        "from hw4lib.trainers import (\n",
        "    LMTrainer,\n",
        ")\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import yaml\n",
        "import gc\n",
        "import torch\n",
        "from torchinfo import summary\n",
        "import os\n",
        "import json\n",
        "import tarfile\n",
        "import shutil\n",
        "import wandb\n",
        "import yaml\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Q4Ccp-M7Q60"
      },
      "source": [
        "# Implementations\n",
        "\n",
        "- `NOTE`: All of these implementations have detailed specification, implementation details, and hints in their respective source files. Make sure to read all of them in their entirety to understand the implementation details!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vqefJri7Q60"
      },
      "source": [
        "## MyTorch Implementations\n",
        "- Modify your `Linear` implementation from HW1P1 to support arbitrary number of dimensions in `mytorch/nn/linear.py`.\n",
        "- Modify your `Softmax` implementation from HW1P1 to support arbitrary number of dimensions in `mytorch/nn/activation.py`.\n",
        "- Implement the `ScaledDotProductAttention` class in `mytorch/nn/scaled_dot_product_attention.py`.\n",
        "- Implement the `MultiHeadAttention` class in `mytorch/nn/multi_head_attention.py`.\n",
        "- Run the cell below to check your implementations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2hxzUzzW7Q60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[95m================================================================================\n",
            "Running tests for category: Linear\n",
            "--------------------------------------------------------------------------------\u001b[0m\n",
            "\n",
            "\u001b[94m[01/01]    Running:  Linear Tests\u001b[0m\n",
            "Testing Linear Layer ...\n",
            "Test Passed: Linear Forward\n",
            "Test Passed: Linear Backward\n",
            "\u001b[92m[01/01]    PASSED:   Linear Tests\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[95m================================================================================\n",
            "Running tests for category: Softmax\n",
            "--------------------------------------------------------------------------------\u001b[0m\n",
            "\n",
            "\u001b[94m[01/01]    Running:  Softmax Tests\u001b[0m\n",
            "Testing Softmax ...\n",
            "Test Passed: Softmax Forward\n",
            "Test Passed: Softmax Backward\n",
            "\u001b[92m[01/01]    PASSED:   Softmax Tests\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[95m================================================================================\n",
            "Running tests for category: ScaledDotProductAttention\n",
            "--------------------------------------------------------------------------------\u001b[0m\n",
            "\n",
            "\u001b[94m[01/01]    Running:  ScaledDotProductAttention Tests\u001b[0m\n",
            "Testing Scaled Dot Product Attention ...\n",
            "Test Passed: Scaled Dot Product Attention Forward\n",
            "Test Passed: Scaled Dot Product Attention Backward\n",
            "\u001b[92m[01/01]    PASSED:   ScaledDotProductAttention Tests\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[95m================================================================================\n",
            "Running tests for category: MultiHeadAttention\n",
            "--------------------------------------------------------------------------------\u001b[0m\n",
            "\n",
            "\u001b[94m[01/01]    Running:  MultiHeadAttention Tests\u001b[0m\n",
            "Testing Multi Head Attention ...\n",
            "Test Passed: Multi Head Attention Forward\n",
            "Test Passed: Multi Head Attention Backward\n",
            "\u001b[92m[01/01]    PASSED:   MultiHeadAttention Tests\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[95m================================================================================\n",
            "                                  Test Summary                                  \n",
            "================================================================================\u001b[0m\n",
            "\u001b[93mCategory:    Linear                        \n",
            "Results:     1/1 tests passed (100.0%)\u001b[0m\n",
            "\u001b[93mCategory:    Softmax                       \n",
            "Results:     1/1 tests passed (100.0%)\u001b[0m\n",
            "\u001b[93mCategory:    ScaledDotProductAttention     \n",
            "Results:     1/1 tests passed (100.0%)\u001b[0m\n",
            "\u001b[93mCategory:    MultiHeadAttention            \n",
            "Results:     1/1 tests passed (100.0%)\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python -m tests.test_mytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8hb5VAN7Q60"
      },
      "source": [
        "## Dataset Implementation\n",
        "- Familiarize yourself with the `tokenize`, `encode`, and `decode` methods of the `H4Tokenizer` class in `hw4lib/data/tokenizer.py`. You will need to make use of these methods in both `HW4P1` and `HW4P2` both in the dataset implementations and during decoding.\n",
        "- Implement the `LMDataset` class in `hw4lib/data/lm_dataset.py`.\n",
        "    - You will have to implement parts of `__init__` and completely implement the `__len__`, `__getitem__` and `collate_fn` methods.\n",
        "- Run the cell below to check your implementation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "D1oCYvlJ7Q60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"/home/agcheria/idl_assignment_Fall_2025/HW4/HW4P1/IDL-HW4/IDL-HW4/tests/test_dataset_lm.py\", line 192, in <module>\n",
            "    main()\n",
            "  File \"/home/agcheria/idl_assignment_Fall_2025/HW4/HW4P1/IDL-HW4/IDL-HW4/tests/test_dataset_lm.py\", line 171, in main\n",
            "    train_dataset = LMDataset(\n",
            "                    ^^^^^^^^^^\n",
            "  File \"/home/agcheria/idl_assignment_Fall_2025/HW4/HW4P1/IDL-HW4/IDL-HW4/hw4lib/data/lm_dataset.py\", line 68, in __init__\n",
            "    self.text_files = sorted(os.listdir(self.text_dir))\n",
            "                             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "FileNotFoundError: [Errno 2] No such file or directory: './hw4_data_subset/hw4p1_data/text/train'\n"
          ]
        }
      ],
      "source": [
        "!python -m tests.test_dataset_lm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6R08H787Q60"
      },
      "source": [
        "## Model Implementations\n",
        "#### Overview:\n",
        "- Implement the `CausalMask` and `PadMask` functions in `hw4lib/modules/masks.py` to handle masking.\n",
        "- Implement the `PositionalEncoding` class in `hw4lib/model/positional_encoding.py` to handle positional encoding.\n",
        "- Implement the Transformer Sublayers: `SelfAttentionLayer` and `FeedForwardLayer` classes in `hw4lib/model/sublayers.py`.\n",
        "- Implement the Transformer Layer: `SelfAttentionDecoderLayer` class in `hw4lib/model/decoder_layers.py`.\n",
        "- Implement the `DecoderOnlyTransformer` class in `hw4lib/model/transformers.py`.\n",
        "- Run the cells below to check your implementation.\n",
        "- `NOTE`: Besides the `DecoderOnlyTransformer` (P1 mandatory, P2 optional), you will use all of the above implementations in both `HW4P1` and `HW4P2`!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6m-85zB7Q61"
      },
      "source": [
        "### Masks\n",
        "- Implement the `PadMask` and `CausalMask` functions in `hw4lib/modules/masks.py`.\n",
        "- Run the cell below to check your implementation.\n",
        "- You will need to make use of these masks in both `HW4P1` and `HW4P2`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Di88pr8J7Q61"
      },
      "source": [
        "#### Causal Mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "mAHwBO7m7Q61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[95m================================================================================\n",
            "Running tests for category: CausalMask\n",
            "--------------------------------------------------------------------------------\u001b[0m\n",
            "\n",
            "\u001b[94m[01/01]    Running:  Test the causal mask generation\u001b[0m\n",
            "Testing Causal Mask ...\n",
            "Test Passed: Causal mask generation is correct.\n",
            "\u001b[92m[01/01]    PASSED:   Test the causal mask generation\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[95m================================================================================\n",
            "                                  Test Summary                                  \n",
            "================================================================================\u001b[0m\n",
            "\u001b[93mCategory:    CausalMask                    \n",
            "Results:     1/1 tests passed (100.0%)\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python -m tests.test_mask_causal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCPEtI8X7Q61"
      },
      "source": [
        "#### Padding Mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "UiZusS-H7Q62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[95m================================================================================\n",
            "Running tests for category: PaddingMask\n",
            "--------------------------------------------------------------------------------\u001b[0m\n",
            "\n",
            "\u001b[94m[01/01]    Running:  Test the padding mask generation\u001b[0m\n",
            "Testing Padding Mask ...\n",
            "Test Passed: Padding mask generation is correct.\n",
            "\u001b[92m[01/01]    PASSED:   Test the padding mask generation\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[95m================================================================================\n",
            "                                  Test Summary                                  \n",
            "================================================================================\u001b[0m\n",
            "\u001b[93mCategory:    PaddingMask                   \n",
            "Results:     1/1 tests passed (100.0%)\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python -m tests.test_mask_padding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1ZeV5XM7Q62"
      },
      "source": [
        "#### Optional: Visualize your Masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9UqY1xD_7Q62"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x400 with 3 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Dummy data\n",
        "_d_model   = 64\n",
        "_x         = torch.zeros(4, 20, _d_model)\n",
        "_x_len     = torch.tensor([5, 15, 10, 20])\n",
        "_x_causal  = CausalMask(_x)\n",
        "_x_padding = PadMask(_x, _x_len)\n",
        "\n",
        "# Create figure with two subplots side by side\n",
        "fig, mask_axs = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "# Plot masks\n",
        "masks_and_titles = [\n",
        "    (_x_padding, \"Padding Mask\"),\n",
        "    (_x_causal, \"Causal Mask\")\n",
        "]\n",
        "\n",
        "# Plot each mask\n",
        "images = []\n",
        "for i, (mask, title) in enumerate(masks_and_titles):\n",
        "    im = mask_axs[i].imshow(mask, cmap=\"gray\", aspect='auto')\n",
        "    mask_axs[i].set_title(title, fontsize=8)\n",
        "    images.append(im)\n",
        "\n",
        "# Add colorbar at the bottom\n",
        "fig.subplots_adjust(bottom=0.2)  # Make space for colorbar\n",
        "cbar_ax = fig.add_axes([0.15, 0.1, 0.7, 0.02])  # [left, bottom, width, height]\n",
        "cbar = plt.colorbar(images[0], cax=cbar_ax, orientation='horizontal')\n",
        "cbar.ax.set_xlabel('Mask Values', labelpad=5, fontsize=8)\n",
        "cbar.set_ticks([0, 1])\n",
        "cbar.set_ticklabels(['Attend (0)', 'Ignore/Mask (1)'])\n",
        "cbar.ax.tick_params(labelsize=6)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlkN0B1H7Q63"
      },
      "source": [
        "### Positional Encoding\n",
        "- Implement the `PositionalEncoding` class in `hw4lib/model/positional_encoding.py`.\n",
        "- Run the cell below to check your implementation.\n",
        "- You will need to make use of this positional encoding in both `HW4P1` and `HW4P2`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "LTO-EMdY7Q63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[95m================================================================================\n",
            "Running tests for category: PositionalEncoding\n",
            "--------------------------------------------------------------------------------\u001b[0m\n",
            "\n",
            "\u001b[94m[01/01]    Running:  Test the positional encoding generation\u001b[0m\n",
            "Testing Positional Encoding Shape ...\n",
            "Test Passed: Positional Encoding Shape is Correct\n",
            "Testing Positional Encoding Values ...\n",
            "Test Passed: Positional Encoding Values are Correct\n",
            "Testing Positional Encoding Forward ...\n",
            "Test Passed: Positional Encoding Forward is Correct\n",
            "\u001b[92m[01/01]    PASSED:   Test the positional encoding generation\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[95m================================================================================\n",
            "                                  Test Summary                                  \n",
            "================================================================================\u001b[0m\n",
            "\u001b[93mCategory:    PositionalEncoding            \n",
            "Results:     1/1 tests passed (100.0%)\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python -m tests.test_positional_encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehZGbq5G7Q64"
      },
      "source": [
        "#### Optional: Visualize your Positional Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "5cgKYbz47Q64"
      },
      "outputs": [
        {
          "ename": "NotImplementedError",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNotImplementedError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m d_model = \u001b[32m64\u001b[39m\n\u001b[32m      3\u001b[39m max_len = \u001b[32m100\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m pos_encoding = \u001b[43mPositionalEncoding\u001b[49m\u001b[43m(\u001b[49m\u001b[43md_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43md_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_len\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_len\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m pe = pos_encoding.pe.squeeze(\u001b[32m0\u001b[39m).numpy()  \u001b[38;5;66;03m# Remove batch dimension and convert to numpy\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Create figure with two subplots side by side\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/idl_assignment_Fall_2025/HW4/HW4P1/IDL-HW4/IDL-HW4/hw4lib/model/positional_encoding.py:31\u001b[39m, in \u001b[36mPositionalEncoding.__init__\u001b[39m\u001b[34m(self, d_model, max_len)\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[33;03mInitialize the PositionalEncoding.\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     28\u001b[39m \u001b[33;03m2. Call create_pe_table to initialize positional encoding matrix\u001b[39;00m\n\u001b[32m     29\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m     \n\u001b[32m     30\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m()\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcreate_pe_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43md_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_len\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/idl_assignment_Fall_2025/HW4/HW4P1/IDL-HW4/IDL-HW4/hw4lib/model/positional_encoding.py:46\u001b[39m, in \u001b[36mPositionalEncoding.create_pe_table\u001b[39m\u001b[34m(self, d_model, max_len)\u001b[39m\n\u001b[32m     33\u001b[39m def create_pe_table(self, d_model, max_len):\n\u001b[32m     34\u001b[39m     \"\"\"\n\u001b[32m     35\u001b[39m     Create the positional encoding table.\n\u001b[32m     36\u001b[39m     \n\u001b[32m   (...)\u001b[39m\u001b[32m     43\u001b[39m           of shape (1, max_len, d_model) (in order to broadcast with input tensor)\n\u001b[32m     44\u001b[39m     \"\"\"\n\u001b[32m     45\u001b[39m     # TODO: Implement create_pe_table\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m     # position: (max_len, 1)\n\u001b[32m     47\u001b[39m     position = torch.arange(max_len, dtype=torch.float32).unsqueeze(1)\n\u001b[32m     48\u001b[39m     # div_term for even indices: (d_model/2,)\n",
            "\u001b[31mNotImplementedError\u001b[39m: "
          ]
        }
      ],
      "source": [
        "# Create sample positional encoding\n",
        "d_model = 64\n",
        "max_len = 100\n",
        "pos_encoding = PositionalEncoding(d_model=d_model, max_len=max_len)\n",
        "pe = pos_encoding.pe.squeeze(0).numpy()  # Remove batch dimension and convert to numpy\n",
        "\n",
        "# Create figure with two subplots side by side\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "# Plot 1: Positional encoding matrix\n",
        "im = ax1.imshow(pe, aspect='auto', cmap='RdBu',\n",
        "                extent=[0, d_model, max_len, 0])  # Flip y-axis to show position top-to-bottom\n",
        "plt.colorbar(im, ax=ax1, label='Encoding Value')\n",
        "ax1.set_xlabel('Dimension')\n",
        "ax1.set_ylabel('Position')\n",
        "ax1.set_title('Positional Encoding Matrix')\n",
        "ax1.grid(False)\n",
        "\n",
        "# Plot 2: Sinusoidal patterns\n",
        "dimensions = [0, 15, 31, 47, 63]  # Plot first few dimensions\n",
        "for dim in dimensions:\n",
        "    ax2.plot(pe[:, dim], label=f'dim {dim}')\n",
        "ax2.set_xlabel('Position')\n",
        "ax2.set_ylabel('Encoding Value')\n",
        "ax2.set_title('Sinusoidal Patterns for Different Dimensions')\n",
        "ax2.legend()\n",
        "ax2.grid(True)\n",
        "\n",
        "# Adjust layout to prevent overlap\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSAUWGco7Q64"
      },
      "source": [
        "### Transformer Sublayers\n",
        "- Implement the Transformer Sublayers: `SelfAttentionLayer`, and `FeedForwardLayer` classes in `hw4lib/model/sublayers.py`.\n",
        "- Run the cell below to check your implementation.\n",
        "- You will need to make use of all of these sublayers in both `HW4P1` and `HW4P2`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4auGdGYy7Q64"
      },
      "outputs": [],
      "source": [
        "!python -m tests.test_sublayer_selfattention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DIy1d8757Q64"
      },
      "outputs": [],
      "source": [
        "!python -m tests.test_sublayer_feedforward"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfGn7MqL7Q65"
      },
      "source": [
        "### Transformer Self-Attention Decoder Layer\n",
        "- Implement the Transformer Layer: `SelfAttentionDecoderLayer` class in `hw4lib/model/decoder_layers.py`.\n",
        "- Run the cell below to check your implementation.\n",
        "- You will need to make use of this sublayer in `HW4P2`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S8p-8Uff7Q65"
      },
      "outputs": [],
      "source": [
        "!python -m tests.test_decoderlayer_selfattention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0NW07hn7Q65"
      },
      "source": [
        "### Decoder-Only Transformer\n",
        "\n",
        "- Implement the `DecoderOnlyTransformer` class in `hw4lib/model/transformers.py`.\n",
        "- Run the cell below to check your implementation.\n",
        "- You will need to make use of in `HW4P1` and optionally `HW4P2`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Z1SU9b97Q65"
      },
      "outputs": [],
      "source": [
        "!python -m tests.test_transformer_decoder_only"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSGdoo9J7Q65"
      },
      "source": [
        "## Decoding Implementation\n",
        "- Implement the `generate_greedy` method of the `SequenceGenerator` class in `hw4lib/decoding/sequence_generator.py`.\n",
        "- Run the cell below to check your implementation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ks5wXPYS7Q65"
      },
      "outputs": [],
      "source": [
        "!python -m tests.test_decoding --mode greedy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiM1ynWhzQRp"
      },
      "source": [
        "## Trainer Implementation\n",
        "You will have to do some minor in-filling for the `LMTrainer` class in `hw4lib/trainers/lm_trainer.py` before you can use it.\n",
        "- Fill in the `TODO`s in the `__init__`.\n",
        "- Fill in the `TODO`s in the `_train_epoch`.\n",
        "- Fill in the `TODO`s in the `_validate_epoch`.\n",
        "- Fill in the `TODO`s in the `generate` method.\n",
        "- Fill in the `TODO`s in the `train` method.\n",
        "\n",
        "`WARNING`: There are no test's for this. Implement carefully!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2-j-cKa7Q65"
      },
      "source": [
        "# Experiments\n",
        "From this point onwards you may want to switch to a `GPU` runtime.\n",
        "- `OBJECTIVE`: You must achieve a per-character perplexity ‚â§ 3.5 in order to get points for Task 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nV2GWmKd7Q65"
      },
      "source": [
        "## Config\n",
        "- You can use the `config.yaml` file to set your config for your ablation study.\n",
        "\n",
        "---\n",
        "### Notes:\n",
        "\n",
        "- Set `tokenization: token_type:` to specify your desired tokenization strategy\n",
        "- You will need to set the root path to your `hw4p1_data` folder in `data: root:`. This will depend on your setup. For eg. if you are following out setup instruction:\n",
        "  - `PSC`: `\"/ocean/projects/cis250019p/mzhang23/TA/HW4/hw4p1_data\"`\n",
        "  - `Colab:`: `\"/content/hw4_data/hw4p1_data\"`\n",
        "  - `Kaggle:`: `\"/kaggle/input/s25-hw4-data/hw4p1_data\"`\n",
        "- There's extra configurations in the `optimizer` section which will only be relevant if you decide to use the `create_optimizer` function we've provided in `hw4lib/utils/create_optimizer.py`.\n",
        "- `BE CAREFUL` while setting numeric values. Eg. `1e-4` will get serialized to a `str` while `1.0e-4` gets serialized to float.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLChmBx67Q65"
      },
      "outputs": [],
      "source": [
        "%%writefile config.yaml\n",
        "\n",
        "Name                      : \"Enter-Name-Here\"\n",
        "\n",
        "###### Tokenization ------------------------------------------------------------\n",
        "tokenization:\n",
        "  token_type                : \"char\"       # [char, 1k, 5k, 10k]\n",
        "  token_map :\n",
        "      'char': 'hw4lib/data/tokenizer_jsons/tokenizer_char.json'\n",
        "      '1k'  : 'hw4lib/data/tokenizer_jsons/tokenizer_1000.json'\n",
        "      '5k'  : 'hw4lib/data/tokenizer_jsons/tokenizer_5000.json'\n",
        "      '10k' : 'hw4lib/data/tokenizer_jsons/tokenizer_10000.json'\n",
        "\n",
        "###### Dataset -----------------------------------------------------------------\n",
        "data:                    # Currently setup for Colab assuming out setup\n",
        "  root                 : \"hw4_data/hw4p1_data\"  # TODO: Set the root path of your data\n",
        "  train_partition      : \"train\"  # train\n",
        "  val_partition        : \"val\"    # val\n",
        "  test_partition       : \"test\"   # test\n",
        "  subset               : 1.0      # Load a subset of the data (for debugging, testing, etc\n",
        "  batch_size           : 256      #\n",
        "  NUM_WORKERS          : 2        # Set to 0 for CPU\n",
        "\n",
        "###### Network Specs -------------------------------------------------------------\n",
        "model: # Decoder-Only Language Model (HW4P1)\n",
        "  d_model                   : 256\n",
        "  d_ff                      : 1024\n",
        "  num_layers                : 2\n",
        "  num_heads                 : 2\n",
        "  dropout                   : 0.0\n",
        "  layer_drop_rate           : 0.0\n",
        "  weight_tying              : False\n",
        "\n",
        "###### Common Training Parameters ------------------------------------------------\n",
        "training:\n",
        "  use_wandb                   : True   # Toggle wandb logging\n",
        "  wandb_run_id                : \"none\" # \"none\" or \"run_id\"\n",
        "  resume                      : False  # Resume an existing run (run_id != 'none')\n",
        "  epochs                      : 20\n",
        "  gradient_accumulation_steps : 1\n",
        "  wandb_project               : \"Set-Project-Name-Here\" # wandb project to log to\n",
        "\n",
        "###### Loss ----------------------------------------------------------------------\n",
        "loss: # Just good ol' CrossEntropy\n",
        "  label_smoothing: 0.0\n",
        "\n",
        "###### Optimizer -----------------------------------------------------------------\n",
        "optimizer:\n",
        "  name: \"adam\" # Options: sgd, adam, adamw\n",
        "  lr: 5.0e-4   # Base learning rate\n",
        "\n",
        "  # Common parameters\n",
        "  weight_decay: 0.0001\n",
        "\n",
        "  # Parameter groups\n",
        "  param_groups:\n",
        "    - name: self_attn\n",
        "      patterns: []  # Will match all parameters containing keywords set their learning rate to 0.0001\n",
        "      lr: 0.0001    # LR for self_attn\n",
        "      layer_decay:\n",
        "        enabled: False\n",
        "        decay_rate: 0.8\n",
        "\n",
        "    - name: ffn\n",
        "      patterns: [] # Will match all parameters containing \"ffn\" and set their learning rate to 0.0001\n",
        "      lr: 0.0001   # LR for ffn\n",
        "      layer_decay:\n",
        "        enabled: False\n",
        "        decay_rate: 0.8\n",
        "\n",
        "  # Layer-wise learning rates\n",
        "  layer_decay:\n",
        "    enabled: False\n",
        "    decay_rate: 0.75\n",
        "\n",
        "  # SGD specific parameters\n",
        "  sgd:\n",
        "    momentum: 0.9\n",
        "    nesterov: True\n",
        "    dampening: 0\n",
        "\n",
        "  # Adam specific parameters\n",
        "  adam:\n",
        "    betas: [0.9, 0.999]\n",
        "    eps: 1.0e-8\n",
        "    amsgrad: False\n",
        "\n",
        "  # AdamW specific parameters\n",
        "  adamw:\n",
        "    betas: [0.9, 0.999]\n",
        "    eps: 1.0e-8\n",
        "    amsgrad: False\n",
        "\n",
        "###### Scheduler -----------------------------------------------------------------\n",
        "scheduler:\n",
        "  name: \"cosine\"  # Options: reduce_lr, cosine, cosine_warm\n",
        "\n",
        "  # ReduceLROnPlateau specific parameters\n",
        "  reduce_lr:\n",
        "    mode: \"min\"  # Options: min, max\n",
        "    factor: 0.1  # Factor to reduce learning rate by\n",
        "    patience: 10  # Number of epochs with no improvement after which LR will be reduced\n",
        "    threshold: 0.0001  # Threshold for measuring the new optimum\n",
        "    threshold_mode: \"rel\"  # Options: rel, abs\n",
        "    cooldown: 0  # Number of epochs to wait before resuming normal operation\n",
        "    min_lr: 0.0000001  # Minimum learning rate\n",
        "    eps: 1.0e-8  # Minimal decay applied to lr\n",
        "\n",
        "  # CosineAnnealingLR specific parameters\n",
        "  cosine:\n",
        "    T_max: 15  # Maximum number of iterations\n",
        "    eta_min: 1.0e-8  # Minimum learning rate\n",
        "    last_epoch: -1\n",
        "\n",
        "  # CosineAnnealingWarmRestarts specific parameters\n",
        "  cosine_warm:\n",
        "    T_0: 4  # Number of iterations for the first restart\n",
        "    T_mult: 4  # Factor increasing T_i after each restart\n",
        "    eta_min: 0.0000001  # Minimum learning rate\n",
        "    last_epoch: -1\n",
        "\n",
        "  # Warmup parameters (can be used with any scheduler)\n",
        "  warmup:\n",
        "    enabled: True\n",
        "    type: \"exponential\"  # Options: linear, exponential\n",
        "    epochs: 5\n",
        "    start_factor: 0.1\n",
        "    end_factor: 1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fl_9Vv117Q66"
      },
      "outputs": [],
      "source": [
        "with open('config.yaml', 'r') as file:\n",
        "    config = yaml.safe_load(file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bu56OILL7Q66"
      },
      "source": [
        "## Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XBrysj6-7Q66"
      },
      "outputs": [],
      "source": [
        "Tokenizer = H4Tokenizer(\n",
        "    token_map  = config['tokenization']['token_map'],\n",
        "    token_type = config['tokenization']['token_type']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-vsGdfu7Q66"
      },
      "source": [
        "## Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OCR3fGoL7Q66"
      },
      "outputs": [],
      "source": [
        "train_dataset  = LMDataset(\n",
        "    partition  = config['data']['train_partition'],\n",
        "    config     = config['data'],\n",
        "    tokenizer  = Tokenizer\n",
        ")\n",
        "\n",
        "val_dataset    = LMDataset(\n",
        "    partition  = config['data']['val_partition'],\n",
        "    config     = config['data'],\n",
        "    tokenizer  = Tokenizer\n",
        ")\n",
        "\n",
        "test_dataset   = LMDataset(\n",
        "    partition  = config['data']['test_partition'],\n",
        "    config     = config['data'],\n",
        "    tokenizer  = Tokenizer\n",
        ")\n",
        "\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qf8Y_COP7Q66"
      },
      "source": [
        "## Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0GajQ0LX7Q66"
      },
      "outputs": [],
      "source": [
        "train_loader    = DataLoader(\n",
        "    dataset     = train_dataset,\n",
        "    batch_size  = config['data']['batch_size'],\n",
        "    shuffle     = True,\n",
        "    num_workers = config['data']['NUM_WORKERS'] if device == 'cuda' else 0,\n",
        "    pin_memory  = True,\n",
        "    collate_fn  = train_dataset.collate_fn\n",
        ")\n",
        "\n",
        "val_loader      = DataLoader(\n",
        "    dataset     = val_dataset,\n",
        "    batch_size  = config['data']['batch_size'],\n",
        "    shuffle     = False,\n",
        "    num_workers = config['data']['NUM_WORKERS'] if device == 'cuda' else 0,\n",
        "    pin_memory  = True,\n",
        "    collate_fn  = val_dataset.collate_fn\n",
        ")\n",
        "\n",
        "test_loader     = DataLoader(\n",
        "    dataset     = test_dataset,\n",
        "    batch_size  = config['data']['batch_size'],\n",
        "    shuffle     = False,\n",
        "    num_workers = config['data']['NUM_WORKERS'] if device == 'cuda' else 0,\n",
        "    pin_memory  = True,\n",
        "    collate_fn  = test_dataset.collate_fn\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLKjKWJQ7Q67"
      },
      "source": [
        "### Dataloader Verification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xY40PhyN7Q67"
      },
      "outputs": [],
      "source": [
        "verify_dataloader(train_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Shfm0w7E7Q67"
      },
      "outputs": [],
      "source": [
        "verify_dataloader(val_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dlP3xkCg7Q67"
      },
      "outputs": [],
      "source": [
        "verify_dataloader(test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCrlXlZH7Q67"
      },
      "source": [
        "## Calculate Max Transcript Length\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIGxOLDU7Q67"
      },
      "source": [
        "Calculating the maximum transcript length across your dataset is a crucial step when working with certain transformer models.\n",
        "-  We'll use sinusoidal positional encodings that must be precomputed up to a fixed maximum length.\n",
        "- This maximum length is a hyperparameter that determines:\n",
        "  - How long of a sequence your model can process\n",
        "  - The size of your positional encoding matrix\n",
        "  - Memory requirements during training and inference\n",
        "- `Requirements`: For this assignment, ensure your positional encodings can accommodate at least the longest sequence in your dataset to prevent truncation. However, you can set this value higher if you anticipate using your language model to work with longer sequences in future tasks (hint: this might be useful for P2! üòâ)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iWAWHucJ7Q67"
      },
      "outputs": [],
      "source": [
        "max_transcript_length = max(train_dataset.text_max_len, val_dataset.text_max_len, test_dataset.text_max_len)\n",
        "print(\"=\"*50)\n",
        "print(f\"{'Global Max Transcript Length':<30} : {max_transcript_length}\")\n",
        "print(\"=\"*50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ot4OuRE27Q67"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qL2-8IbL7Q67"
      },
      "outputs": [],
      "source": [
        "model_config = config['model']\n",
        "model_config.update({\n",
        "    'max_len': max_transcript_length,\n",
        "    'num_classes': Tokenizer.vocab_size\n",
        "})\n",
        "model = DecoderOnlyTransformer(**model_config)\n",
        "\n",
        "# Get some inputs from the text loader\n",
        "for batch in train_loader:\n",
        "    shifted_transcripts, golden_transcripts, transcript_lengths = batch\n",
        "    print(\"Shape of shifted_transcripts : \", shifted_transcripts.shape)\n",
        "    print(\"Shape of golden_transcripts  : \", golden_transcripts.shape)\n",
        "    print(\"Shape of transcript_lengths  : \", transcript_lengths.shape)\n",
        "    break\n",
        "\n",
        "model_stats = summary(model, input_data=[shifted_transcripts, transcript_lengths])\n",
        "print(model_stats)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SH973f3x7Q67"
      },
      "source": [
        "## Wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oz7os7UA7Q68"
      },
      "outputs": [],
      "source": [
        "wandb.login(key=\"your_wandb_api_key_here\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQAemeOM7Q68"
      },
      "source": [
        "## Trainer\n",
        "\n",
        "Every time you run the trainer, it will create a new directory in the `expts` folder with the following structure:\n",
        "```\n",
        "expts/\n",
        "    ‚îî‚îÄ‚îÄ {run_name}/\n",
        "        ‚îú‚îÄ‚îÄ config.yaml\n",
        "        ‚îú‚îÄ‚îÄ model_arch.txt\n",
        "        ‚îú‚îÄ‚îÄ checkpoints/\n",
        "        ‚îÇ   ‚îú‚îÄ‚îÄ checkpoint-best-metric-model.pth\n",
        "        ‚îÇ   ‚îî‚îÄ‚îÄ checkpoint-last-epoch-model.pth\n",
        "        ‚îú‚îÄ‚îÄ attn/\n",
        "        ‚îÇ   ‚îî‚îÄ‚îÄ {attention visualizations}\n",
        "        ‚îî‚îÄ‚îÄ text/\n",
        "            ‚îî‚îÄ‚îÄ {generated text outputs}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcvGSnWi7Q68"
      },
      "outputs": [],
      "source": [
        "trainer = LMTrainer(\n",
        "    model=model,\n",
        "    tokenizer=Tokenizer,\n",
        "    config=config,\n",
        "    run_name=\"test-lm\",\n",
        "    config_file=\"config.yaml\",\n",
        "    device=device\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJREaFhqiPrT"
      },
      "source": [
        "### Setup Optimizer and Scheduler\n",
        "\n",
        "You can set your own optimizer and scheduler by setting the class members in the `LMTrainer` class.\n",
        "Eg:\n",
        "```python\n",
        "trainer.optimizer = optim.AdamW(model.parameters(), lr=config['optimizer']['lr'], weight_decay=config['optimizer']['weight_decay'])\n",
        "trainer.scheduler = optim.lr_scheduler.CosineAnnealingLR(trainer.optimizer, T_max=config['training']['epochs'])\n",
        "```\n",
        "\n",
        "We also provide a utility function to create your own optimizer and scheduler with the congig and some extra bells and whistles. You are free to use it or not. Do read their code and documentation to understand how it works (`hw4lib/utils/*`).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WStK_vNzzQRq"
      },
      "source": [
        "#### Setting up the optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GkljGtIPkATt"
      },
      "outputs": [],
      "source": [
        "trainer.optimizer = create_optimizer(\n",
        "    model=model,\n",
        "    opt_config=config['optimizer']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5Luh4WzzQRq"
      },
      "source": [
        "#### Creating a test scheduler and plotting the learning rate schedule"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inatJGBVi3II"
      },
      "outputs": [],
      "source": [
        "test_scheduler = create_scheduler(\n",
        "    optimizer=trainer.optimizer,\n",
        "    scheduler_config=config['scheduler'],\n",
        "    train_loader=train_loader,\n",
        "    gradient_accumulation_steps=config['training']['gradient_accumulation_steps']\n",
        ")\n",
        "\n",
        "plot_lr_schedule(\n",
        "    scheduler=test_scheduler,\n",
        "    num_epochs=config['training']['epochs'],\n",
        "    train_loader=train_loader,\n",
        "    gradient_accumulation_steps=config['training']['gradient_accumulation_steps']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AxafmUnzQRq"
      },
      "source": [
        "#### Setting up the scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yXrwTbqdiPE_"
      },
      "outputs": [],
      "source": [
        "trainer.scheduler = create_scheduler(\n",
        "    optimizer=trainer.optimizer,\n",
        "    scheduler_config=config['scheduler'],\n",
        "    train_loader=train_loader,\n",
        "    gradient_accumulation_steps=config['training']['gradient_accumulation_steps']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XI0dHJB7Q68"
      },
      "source": [
        "# Train\n",
        "- Set your epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nugAKoOw7Q68"
      },
      "outputs": [],
      "source": [
        "trainer.train(train_loader, val_loader, epochs=config['training']['epochs'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j55r9gK_7Q68"
      },
      "source": [
        "# Evaluate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72D0yzHr7Q68"
      },
      "outputs": [],
      "source": [
        "test_metrics, test_generation_results = trainer.evaluate(test_loader)\n",
        "# Cleanup\n",
        "trainer.cleanup()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHw8LJp07Q68"
      },
      "source": [
        "# Submission\n",
        "To submit your assignment, you will need to create a `handin.tar` with the following directory structure:\n",
        "\n",
        "```\n",
        "handin/\n",
        "‚îú‚îÄ‚îÄ mytorch/                     # Your implemented modules\n",
        "‚îú‚îÄ‚îÄ test_metrics.json            # Results from evaluation\n",
        "‚îú‚îÄ‚îÄ test_generated_results.json  # Sample text generations\n",
        "‚îî‚îÄ‚îÄ model_arch.txt               # Model architecture summary\n",
        "```\n",
        "\n",
        "- Simply run the cell below once you are satisfied with your current state and this will create the `handin.tar` file.\n",
        "- After running the above cell, you should see the handin.tar file in the current directory\n",
        "- Upload the `handin.tar` file to the `HW4P1` assignment on Autolab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVSPaoOF7Q68"
      },
      "outputs": [],
      "source": [
        "# Create temporary handin directory\n",
        "if os.path.exists('handin'):\n",
        "    shutil.rmtree('handin')\n",
        "os.makedirs('handin')\n",
        "\n",
        "# Copy mytorch directory\n",
        "shutil.copytree('mytorch', 'handin/mytorch')\n",
        "\n",
        "# Save final results\n",
        "with open('handin/test_metrics.json', 'w') as f:\n",
        "    json.dump(test_metrics, f, indent=4)\n",
        "\n",
        "with open('handin/test_generated_results.json', 'w') as f:\n",
        "    json.dump(test_generation_results['greedy'], f, indent=4)\n",
        "\n",
        "# Save model architecture\n",
        "with open('handin/model_arch.txt', 'w') as f:\n",
        "    f.write(str(model_stats))\n",
        "\n",
        "# Create tar file with all exclusions handled by filter\n",
        "with tarfile.open('handin.tar', 'w') as tar:\n",
        "    def filter_files(tarinfo):\n",
        "        # Skip unwanted files\n",
        "        if any(pattern in tarinfo.name for pattern in [\n",
        "            '.DS_Store',\n",
        "            '__pycache__',\n",
        "            '.pyc'\n",
        "        ]):\n",
        "            return None\n",
        "        return tarinfo\n",
        "\n",
        "    tar.add('handin', arcname='handin', filter=filter_files)\n",
        "\n",
        "# Cleanup\n",
        "shutil.rmtree('handin')\n",
        "\n",
        "print(\"Created handin.tar successfully!\")\n",
        "\n",
        "## After running the above cell, you should see the handin.tar file in the current directory\n",
        "!ls"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "qQG51p6e7Q6x"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "hw4",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
