===============================================================================================
Layer (type:depth-idx)                        Output Shape              Param #
===============================================================================================
EncoderDecoderTransformer                     [16, 100, 5000]           512
├─SpeechEmbedding: 1-1                        [16, 497, 256]            --
│    └─Conv2DSubsampling: 2-1                 [16, 497, 256]            --
│    │    └─Sequential: 3-1                   [16, 256, 497, 76]        592,640
│    │    └─Linear: 3-2                       [16, 497, 256]            4,980,992
│    │    └─Dropout: 3-3                      [16, 497, 256]            --
├─PositionalEncoding: 1-2                     [16, 497, 256]            --
├─Dropout: 1-3                                [16, 497, 256]            --
├─ModuleList: 1-4                             --                        --
│    └─SelfAttentionEncoderLayer: 2-2         [16, 497, 256]            --
│    │    └─SelfAttentionLayer: 3-4           [16, 497, 256]            263,680
│    │    └─FeedForwardLayer: 3-5             [16, 497, 256]            526,080
│    └─SelfAttentionEncoderLayer: 2-3         [16, 497, 256]            --
│    │    └─SelfAttentionLayer: 3-6           [16, 497, 256]            263,680
│    │    └─FeedForwardLayer: 3-7             [16, 497, 256]            526,080
│    └─SelfAttentionEncoderLayer: 2-4         [16, 497, 256]            --
│    │    └─SelfAttentionLayer: 3-8           [16, 497, 256]            263,680
│    │    └─FeedForwardLayer: 3-9             [16, 497, 256]            526,080
│    └─SelfAttentionEncoderLayer: 2-5         [16, 497, 256]            --
│    │    └─SelfAttentionLayer: 3-10          [16, 497, 256]            263,680
│    │    └─FeedForwardLayer: 3-11            [16, 497, 256]            526,080
├─LayerNorm: 1-5                              [16, 497, 256]            512
├─Sequential: 1-6                             [16, 497, 5000]           --
│    └─Linear: 2-6                            [16, 497, 5000]           1,285,000
│    └─LogSoftmax: 2-7                        [16, 497, 5000]           --
├─Embedding: 1-7                              [16, 100, 256]            1,280,000
├─PositionalEncoding: 1-8                     [16, 100, 256]            --
├─Dropout: 1-9                                [16, 100, 256]            --
├─ModuleList: 1-10                            --                        --
│    └─CrossAttentionDecoderLayer: 2-8        [16, 100, 256]            --
│    │    └─SelfAttentionLayer: 3-12          [16, 100, 256]            263,680
│    │    └─CrossAttentionLayer: 3-13         [16, 100, 256]            263,680
│    │    └─FeedForwardLayer: 3-14            [16, 100, 256]            526,080
│    └─CrossAttentionDecoderLayer: 2-9        [16, 100, 256]            --
│    │    └─SelfAttentionLayer: 3-15          [16, 100, 256]            263,680
│    │    └─CrossAttentionLayer: 3-16         [16, 100, 256]            263,680
│    │    └─FeedForwardLayer: 3-17            [16, 100, 256]            526,080
│    └─CrossAttentionDecoderLayer: 2-10       [16, 100, 256]            --
│    │    └─SelfAttentionLayer: 3-18          [16, 100, 256]            263,680
│    │    └─CrossAttentionLayer: 3-19         [16, 100, 256]            263,680
│    │    └─FeedForwardLayer: 3-20            [16, 100, 256]            526,080
│    └─CrossAttentionDecoderLayer: 2-11       [16, 100, 256]            --
│    │    └─SelfAttentionLayer: 3-21          [16, 100, 256]            263,680
│    │    └─CrossAttentionLayer: 3-22         [16, 100, 256]            263,680
│    │    └─FeedForwardLayer: 3-23            [16, 100, 256]            526,080
├─LayerNorm: 1-11                             [16, 100, 256]            512
├─Linear: 1-12                                [16, 100, 5000]           1,285,000
===============================================================================================
Total params: 16,797,968
Trainable params: 16,797,968
Non-trainable params: 0
Total mult-adds (Units.GIGABYTES): 358.42
===============================================================================================
Input size (MB): 5.13
Forward/backward pass size (MB): 3495.17
Params size (MB): 54.56
Estimated Total Size (MB): 3554.86
===============================================================================================