{
  "parameter_count": 18294505,
  "model_architecture": "ASRModel(\n  (time_mask): TimeMasking()\n  (freq_mask): FrequencyMasking()\n  (augmentations): Sequential(\n    (0): Permute()\n    (1): TimeMasking()\n    (2): FrequencyMasking()\n    (3): Permute()\n  )\n  (encoder): Encoder(\n    (embedding): Sequential(\n      (0): Conv1d(28, 64, kernel_size=(15,), stride=(2,), padding=(1,))\n      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): SiLU(inplace=True)\n      (3): EfficientBlock1D(\n        (expand_conv): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n        (expand_bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (expand_act): SiLU(inplace=True)\n        (depthwise_conv): Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,), groups=256, bias=False)\n        (depthwise_bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (depthwise_act): SiLU(inplace=True)\n        (project_conv): Conv1d(256, 128, kernel_size=(1,), stride=(1,), bias=False)\n        (project_bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (4): EfficientBlock1D(\n        (expand_conv): Conv1d(128, 512, kernel_size=(1,), stride=(1,), bias=False)\n        (expand_bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (expand_act): SiLU(inplace=True)\n        (depthwise_conv): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,), groups=512, bias=False)\n        (depthwise_bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (depthwise_act): SiLU(inplace=True)\n        (project_conv): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n        (project_bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (5): EfficientBlock1D(\n        (expand_conv): Conv1d(256, 1024, kernel_size=(1,), stride=(1,), bias=False)\n        (expand_bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (expand_act): SiLU(inplace=True)\n        (depthwise_conv): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,), padding=(2,), groups=1024, bias=False)\n        (depthwise_bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (depthwise_act): SiLU(inplace=True)\n        (project_conv): Conv1d(1024, 256, kernel_size=(1,), stride=(1,), bias=False)\n        (project_bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (6): EfficientBlock1D(\n        (expand_conv): Conv1d(256, 1024, kernel_size=(1,), stride=(1,), bias=False)\n        (expand_bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (expand_act): SiLU(inplace=True)\n        (depthwise_conv): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,), padding=(2,), groups=1024, bias=False)\n        (depthwise_bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (depthwise_act): SiLU(inplace=True)\n        (project_conv): Conv1d(1024, 256, kernel_size=(1,), stride=(1,), bias=False)\n        (project_bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (lstm_layers): ModuleList(\n      (0): pBLSTM(\n        (blstm): LSTM(512, 512, num_layers=3, dropout=0.3, bidirectional=True)\n      )\n      (1): LockedDropout(p=0.25)\n    )\n  )\n  (decoder): Decoder(\n    (mlp): Sequential(\n      (0): Permute()\n      (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): Permute()\n      (3): Linear(in_features=1024, out_features=128, bias=True)\n      (4): GELU(approximate='none')\n      (5): Linear(in_features=128, out_features=64, bias=True)\n      (6): GELU(approximate='none')\n      (7): Linear(in_features=64, out_features=41, bias=True)\n    )\n    (softmax): LogSoftmax(dim=2)\n  )\n)"
}